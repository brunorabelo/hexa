{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:00:46.537790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 15:00:46.751022: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-04 15:00:47.487161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 15:00:47.487210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 15:00:47.487214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:00:49.316475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2022-12-04 15:00:49.316515: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: danilo-Nitro-AN515-58\n",
      "2022-12-04 15:00:49.316520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: danilo-Nitro-AN515-58\n",
      "2022-12-04 15:00:49.316636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2022-12-04 15:00:49.316656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.60.11\n",
      "2022-12-04 15:00:49.316659: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 525.60.11 does not match DSO version 510.108.3 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features\n",
    "train_data[\"url_count\"] = train_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"text_len\"] = train_data[\"text\"].apply(lambda s: len(s))\n",
    "train_data[\"hashtags_count\"] = train_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"day\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "train_data[\"hour\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "\n",
    "# indicators of keywords\n",
    "train_data[\"Macron\"] =  train_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "train_data[\"Zemmour\"] =  train_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "train_data[\"Melenchon\"] =  train_data[\"text\"].apply(lambda s: (\"melenchon\" in s.replace(\"é\",\"e\").lower().split()))\n",
    "train_data[\"rt\"] =  train_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful columns\n",
    "train_data_filtered = train_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>url_count</th>\n",
       "      <th>text_len</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>Melenchon</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3682</td>\n",
       "      <td>453535</td>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1016</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>28234</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13957</td>\n",
       "      <td>25311</td>\n",
       "      <td>10841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353964</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1509</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353965</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>11166</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353966</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1888</td>\n",
       "      <td>712</td>\n",
       "      <td>3086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353967</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>486</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353969 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        retweets_count  favorites_count  followers_count  statuses_count  \\\n",
       "0                    3                0             3682          453535   \n",
       "1                    0                0               86            1016   \n",
       "2                    3                1             1944           28234   \n",
       "3                    0                0                1            1072   \n",
       "4                    0                0            13957           25311   \n",
       "...                ...              ...              ...             ...   \n",
       "353964               0                0               34            1509   \n",
       "353965               0                0               89           11166   \n",
       "353966               3                0             1888             712   \n",
       "353967               0                0              139             486   \n",
       "353968               0                0                0              82   \n",
       "\n",
       "        friends_count  verified  url_count  text_len  hashtags_count  day  \\\n",
       "0                3628         0        0.0        34             0.0   11   \n",
       "1                 284         0        0.0         9             0.0   19   \n",
       "2                1995         0        0.0        19             0.0   15   \n",
       "3                   0         0        1.0       123             0.0   14   \n",
       "4               10841         0        0.0        26             0.0   14   \n",
       "...               ...       ...        ...       ...             ...  ...   \n",
       "353964             55         0        1.0        30             0.0   16   \n",
       "353965            127         0        0.0        69             0.0   12   \n",
       "353966           3086         0        0.0        29             0.0   18   \n",
       "353967            320         0        0.0        24             0.0   11   \n",
       "353968             24         0        0.0        45             0.0   18   \n",
       "\n",
       "        hour  Macron  Zemmour  Melenchon     rt  \n",
       "0          5    True    False      False   True  \n",
       "1         12   False    False      False  False  \n",
       "2         18   False    False      False  False  \n",
       "3         11   False    False      False  False  \n",
       "4         11    True    False      False  False  \n",
       "...      ...     ...      ...        ...    ...  \n",
       "353964    13   False    False      False  False  \n",
       "353965     8   False    False      False  False  \n",
       "353966    12   False     True      False  False  \n",
       "353967     8   False    False      False  False  \n",
       "353968    11    True    False      False  False  \n",
       "\n",
       "[353969 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353969, 15) (353969, 25, 16)\n"
     ]
    }
   ],
   "source": [
    "emb_matrix = np.load(\"data/train_emb_matrix.npy\")\n",
    "print(train_data_filtered.shape, emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalizar colunas embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 3682, 453535, 3628, 0, 0.0, 34, 0.0, 11, 5, True, False,\n",
       "        False, True],\n",
       "       [3, 0, 3682, 453535, 3628, 0, 0.0, 34, 0.0, 11, 5, True, False,\n",
       "        False, True],\n",
       "       [3, 0, 3682, 453535, 3628, 0, 0.0, 34, 0.0, 11, 5, True, False,\n",
       "        False, True],\n",
       "       [3, 0, 3682, 453535, 3628, 0, 0.0, 34, 0.0, 11, 5, True, False,\n",
       "        False, True],\n",
       "       [3, 0, 3682, 453535, 3628, 0, 0.0, 34, 0.0, 11, 5, True, False,\n",
       "        False, True]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_newdim = np.expand_dims(np.array(train_data_filtered), axis=1)\n",
    "data_reshaped = np.broadcast_to(data_newdim, (emb_matrix.shape[0], emb_matrix.shape[1], train_data_filtered.shape[1]))\n",
    "data_reshaped[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix = np.concatenate((data_reshaped, emb_matrix), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 3682 453535 3628 0 0.0 34 0.0 11 5 True False False True\n",
      "  0.18788284063339233 -0.5350038409233093 -1.7558887004852295\n",
      "  0.6010056138038635 -0.38633257150650024 0.23139137029647827\n",
      "  -0.8143761157989502 0.6429756879806519 0.07032456994056702\n",
      "  0.047739773988723755 -1.0532739162445068 -0.04242870211601257\n",
      "  0.4343041181564331 -0.9819753766059875 -0.49964916706085205\n",
      "  1.6986557245254517]\n",
      " [3 0 3682 453535 3628 0 0.0 34 0.0 11 5 True False False True\n",
      "  0.37392178177833557 1.6400281190872192 -0.06540881097316742\n",
      "  -0.5598422288894653 -0.7594510316848755 -0.1807458996772766\n",
      "  -0.2969696819782257 0.3544090688228607 -0.4949268400669098\n",
      "  0.5475368499755859 0.7976458668708801 -0.10759757459163666\n",
      "  0.3659772574901581 -0.044347986578941345 -0.588219165802002\n",
      "  -0.4794001579284668]]\n"
     ]
    }
   ],
   "source": [
    "print(full_matrix[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful columns\n",
    "train_data_filtered = train_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "# train_data_filtered = train_data.loc[:, [\"retweets_count\",\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\",\n",
    "#                                  \"hashtags_count\",\"hour\",\"verified\",\"url_count\",\"text_len\",\"rt\",\"Macron\",\"Zemmour\",\"Melenchon\"]]\n",
    "\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(train_data_filtered.drop(\"retweets_count\", axis=1),\n",
    "                                                    train_data_filtered[\"retweets_count\"],\n",
    "                                                    random_state=42, test_size=0.1)\n",
    "\n",
    "# Standardize the data\n",
    "normal_columns = train_data_filtered.drop([\"hour\", \"verified\", \"Macron\", \"Zemmour\", \"Melenchon\", \"url_count\", \"rt\", \"retweets_count\"], axis=1).columns\n",
    "mu, sigma = X_train[normal_columns].mean(axis=0), X_train[normal_columns].std(axis=0)\n",
    "X_train.loc[:, normal_columns] = (X_train[normal_columns] - mu) / sigma\n",
    "X_eval.loc[:, normal_columns] = (X_eval[normal_columns] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(64, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "# ])\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "n_timesteps = 40\n",
    "input_features = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(30, return_sequences=True), input_shape=(n_timesteps, input_features)))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "# optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4)\n",
    "# model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train.values.astype(np.float32), y_train.values.astype(np.float32), epochs=150, batch_size=256,\n",
    "         validation_data=(X_eval.values.astype(np.float32), y_eval.values.astype(np.float32)), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"loss\"], 'b', label='Training loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], 'g', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_eval.values.astype(np.float32),  y_eval.values.astype(np.float32), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train.values.astype(np.float32))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[\"favorites_count\"], model.predict(X_train))\n",
    "# plt.scatter(X_train[\"favorites_count\"], y_train.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\")\n",
    "tweets = eval_data[\"TweetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data[\"url_count\"] = eval_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"text_len\"] = eval_data[\"text\"].apply(lambda s: len(s))\n",
    "eval_data[\"hashtags_count\"] = eval_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"day\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "eval_data[\"hour\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "eval_data[\"Macron\"] =  eval_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "eval_data[\"Zemmour\"] =  eval_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "eval_data[\"Melenchon\"] =  eval_data[\"text\"].apply(lambda s: (\"melenchon\" in s.lower().split()))\n",
    "eval_data[\"rt\"] =  eval_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))\n",
    "\n",
    "# print(\"sentiment analysis...\")\n",
    "# eval_data[\"compound\"] =  eval_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])\n",
    "\n",
    "eval_data = eval_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "\n",
    "# normalize\n",
    "eval_data.loc[:, normal_columns] = (eval_data.loc[:, normal_columns] - mu) / sigma\n",
    "\n",
    "print(eval_data)\n",
    "\n",
    "pred = model.predict(eval_data.values.astype(np.float32))\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# output normalization\n",
    "for i,p in enumerate(pred):\n",
    "    if p<0: pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/predictions.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"retweets_count\"])\n",
    "    for index, prediction in enumerate(pred):\n",
    "        writer.writerow([str(tweets[index]) , str(int(prediction))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b76f9357de510751682414c7cddbaacea429d985ca72e90da955bd41bf6fe1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

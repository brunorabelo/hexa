{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features\n",
    "train_data[\"url_count\"] = train_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"text_len\"] = train_data[\"text\"].apply(lambda s: len(s))\n",
    "train_data[\"hashtags_count\"] = train_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"day\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "train_data[\"hour\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "\n",
    "# text features\n",
    "train_data[\"avg_word_len\"] = train_data[\"text\"].apply(lambda s: np.mean([len(w) for w in s.split()]))\n",
    "train_data[\"rep_words_freq\"] = train_data[\"text\"].apply(lambda s: np.mean(len(list(set(s.split())))/len(s.split())))\n",
    "train_data[\"rep_chars_freq\"] = train_data[\"text\"].apply(lambda s: np.mean(len(list(set(s)))/len(list(s))))\n",
    "train_data[\"max_char_freq\"] = train_data[\"text\"].apply(lambda s: max( [s.count(c) for c in list(set(s))] )   /len(list(s)))\n",
    "train_data[\"avg_word_count\"] = train_data[\"text\"].apply(lambda s: len(s.split()))\n",
    "\n",
    "# indicators of keywords\n",
    "train_data[\"Macron\"] =  train_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "train_data[\"Zemmour\"] =  train_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "train_data[\"Melenchon\"] =  train_data[\"text\"].apply(lambda s: (\"melenchon\" in s.replace(\"é\",\"e\").lower().split()))\n",
    "train_data[\"rt\"] =  train_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outlier removal\n",
    "# train_data = train_data[train_data[\"retweets_count\"] <= 40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis...\n"
     ]
    }
   ],
   "source": [
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "# print(\"sentiment analysis...\")\n",
    "# train_data[\"compound\"] =  train_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>verified</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>rep_words_freq</th>\n",
       "      <th>rep_chars_freq</th>\n",
       "      <th>max_char_freq</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>Melenchon</th>\n",
       "      <th>rt</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rt refarcir macron ans nom prépare</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3682</td>\n",
       "      <td>453535</td>\n",
       "      <td>3628</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>populaire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1016</td>\n",
       "      <td>284</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>faut dégager cinglé</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>28234</td>\n",
       "      <td>1995</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enseignants mettre prescriptions président rép...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/rytlted08g']</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mafieuse oppressive macron</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13957</td>\n",
       "      <td>25311</td>\n",
       "      <td>10841</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353964</th>\n",
       "      <td>353964</td>\n",
       "      <td>gonflette tour raciste frustré</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1509</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/pma33zhslx']</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353965</th>\n",
       "      <td>353965</td>\n",
       "      <td>france caste crapuleuse encadrée gangsters irr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>11166</td>\n",
       "      <td>127</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353966</th>\n",
       "      <td>353966</td>\n",
       "      <td>eric zemmour français berbère</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1888</td>\n",
       "      <td>712</td>\n",
       "      <td>3086</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353967</th>\n",
       "      <td>353967</td>\n",
       "      <td>gauchistes dépression pq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>486</td>\n",
       "      <td>320</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353968</th>\n",
       "      <td>353968</td>\n",
       "      <td>algérie emmanuel macron grande histoire amour</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353967 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0                 rt refarcir macron ans nom prépare   \n",
       "1                1                                          populaire   \n",
       "2                2                                faut dégager cinglé   \n",
       "3                3  enseignants mettre prescriptions président rép...   \n",
       "4                4                         mafieuse oppressive macron   \n",
       "...            ...                                                ...   \n",
       "353964      353964                     gonflette tour raciste frustré   \n",
       "353965      353965  france caste crapuleuse encadrée gangsters irr...   \n",
       "353966      353966                      eric zemmour français berbère   \n",
       "353967      353967                           gauchistes dépression pq   \n",
       "353968      353968      algérie emmanuel macron grande histoire amour   \n",
       "\n",
       "        retweets_count  favorites_count  followers_count  statuses_count  \\\n",
       "0                    3                0             3682          453535   \n",
       "1                    0                0               86            1016   \n",
       "2                    3                1             1944           28234   \n",
       "3                    0                0                1            1072   \n",
       "4                    0                0            13957           25311   \n",
       "...                ...              ...              ...             ...   \n",
       "353964               0                0               34            1509   \n",
       "353965               0                0               89           11166   \n",
       "353966               3                0             1888             712   \n",
       "353967               0                0              139             486   \n",
       "353968               0                0                0              82   \n",
       "\n",
       "        friends_count mentions                         urls  verified  ...  \\\n",
       "0                3628       []                           []         0  ...   \n",
       "1                 284       []                           []         0  ...   \n",
       "2                1995       []                           []         0  ...   \n",
       "3                   0       []  ['https://t.co/rytlted08g']         0  ...   \n",
       "4               10841       []                           []         0  ...   \n",
       "...               ...      ...                          ...       ...  ...   \n",
       "353964             55       []  ['https://t.co/pma33zhslx']         0  ...   \n",
       "353965            127       []                           []         0  ...   \n",
       "353966           3086       []                           []         0  ...   \n",
       "353967            320       []                           []         0  ...   \n",
       "353968             24       []                           []         0  ...   \n",
       "\n",
       "       avg_word_len  rep_words_freq  rep_chars_freq  max_char_freq  \\\n",
       "0          4.833333        1.000000        0.411765       0.205882   \n",
       "1          9.000000        1.000000        0.888889       0.222222   \n",
       "2          5.666667        1.000000        0.736842       0.157895   \n",
       "3          7.857143        0.928571        0.170732       0.138211   \n",
       "4          8.000000        1.000000        0.538462       0.153846   \n",
       "...             ...             ...             ...            ...   \n",
       "353964     6.750000        1.000000        0.500000       0.166667   \n",
       "353965     9.000000        1.000000        0.260870       0.159420   \n",
       "353966     6.500000        1.000000        0.551724       0.172414   \n",
       "353967     7.333333        1.000000        0.708333       0.166667   \n",
       "353968     6.666667        1.000000        0.377778       0.111111   \n",
       "\n",
       "        avg_word_count  Macron  Zemmour  Melenchon     rt  compound  \n",
       "0                    6    True    False      False   True    0.0000  \n",
       "1                    1   False    False      False  False    0.0000  \n",
       "2                    3   False    False      False  False    0.0000  \n",
       "3                   14   False    False      False  False    0.0000  \n",
       "4                    3    True    False      False  False   -0.4019  \n",
       "...                ...     ...      ...        ...    ...       ...  \n",
       "353964               4   False    False      False  False    0.0000  \n",
       "353965               7   False    False      False  False    0.0000  \n",
       "353966               4   False     True      False  False    0.0000  \n",
       "353967               3   False    False      False  False    0.0000  \n",
       "353968               6    True    False      False  False    0.0000  \n",
       "\n",
       "[353967 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful columns\n",
    "train_data_filtered = train_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "# train_data_filtered = train_data.loc[:, [\"retweets_count\",\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\",\n",
    "#                                  \"hashtags_count\",\"hour\",\"verified\",\"url_count\",\"text_len\",\"rt\",\"Macron\",\"Zemmour\",\"Melenchon\"]]\n",
    "\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(train_data_filtered.drop(\"retweets_count\", axis=1),\n",
    "                                                    train_data_filtered[\"retweets_count\"],\n",
    "                                                    random_state=42, test_size=0.1)\n",
    "\n",
    "# Standardize the data\n",
    "normal_columns = train_data_filtered.drop([\"hour\", \"verified\", \"Macron\", \"Zemmour\", \"Melenchon\", \"url_count\", \"rt\", \"retweets_count\"], axis=1).columns\n",
    "mu, sigma = X_train[normal_columns].mean(axis=0), X_train[normal_columns].std(axis=0)\n",
    "X_train.loc[:, normal_columns] = (X_train[normal_columns] - mu) / sigma\n",
    "X_eval.loc[:, normal_columns] = (X_eval[normal_columns] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "# optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4)\n",
    "# model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 15.1474 - val_loss: 15.7501\n",
      "Epoch 2/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 10.7590 - val_loss: 7.4308\n",
      "Epoch 3/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 7.0740 - val_loss: 7.1695\n",
      "Epoch 4/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.9069 - val_loss: 7.0469\n",
      "Epoch 5/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.8421 - val_loss: 7.1152\n",
      "Epoch 6/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.7818 - val_loss: 6.9519\n",
      "Epoch 7/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.7330 - val_loss: 7.0741\n",
      "Epoch 8/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.6718 - val_loss: 6.9497\n",
      "Epoch 9/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.6097 - val_loss: 6.9819\n",
      "Epoch 10/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.5785 - val_loss: 6.9420\n",
      "Epoch 11/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.5254 - val_loss: 6.8768\n",
      "Epoch 12/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.5037 - val_loss: 6.7602\n",
      "Epoch 13/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.4702 - val_loss: 6.7580\n",
      "Epoch 14/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.4332 - val_loss: 6.7423\n",
      "Epoch 15/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.4054 - val_loss: 6.7141\n",
      "Epoch 16/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.3902 - val_loss: 6.7547\n",
      "Epoch 17/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.3758 - val_loss: 6.7069\n",
      "Epoch 18/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.3440 - val_loss: 6.6689\n",
      "Epoch 19/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.3258 - val_loss: 6.6578\n",
      "Epoch 20/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.3175 - val_loss: 6.6428\n",
      "Epoch 21/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.2971 - val_loss: 6.7232\n",
      "Epoch 22/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2754 - val_loss: 6.5993\n",
      "Epoch 23/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.2546 - val_loss: 6.5948\n",
      "Epoch 24/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2516 - val_loss: 6.5540\n",
      "Epoch 25/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2457 - val_loss: 6.5967\n",
      "Epoch 26/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.2293 - val_loss: 6.5312\n",
      "Epoch 27/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.2093 - val_loss: 6.5077\n",
      "Epoch 28/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.1904 - val_loss: 6.5467\n",
      "Epoch 29/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1923 - val_loss: 6.5377\n",
      "Epoch 30/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1768 - val_loss: 6.5543\n",
      "Epoch 31/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1573 - val_loss: 6.5269\n",
      "Epoch 32/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1573 - val_loss: 6.4321\n",
      "Epoch 33/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1315 - val_loss: 6.7211\n",
      "Epoch 34/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1298 - val_loss: 6.4511\n",
      "Epoch 35/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.1350 - val_loss: 6.4447\n",
      "Epoch 36/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1124 - val_loss: 6.4250\n",
      "Epoch 37/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.1075 - val_loss: 6.4041\n",
      "Epoch 38/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0921 - val_loss: 6.4077\n",
      "Epoch 39/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0907 - val_loss: 6.4200\n",
      "Epoch 40/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.0681 - val_loss: 6.3889\n",
      "Epoch 41/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.0732 - val_loss: 6.4505\n",
      "Epoch 42/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0445 - val_loss: 6.3973\n",
      "Epoch 43/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0524 - val_loss: 6.3951\n",
      "Epoch 44/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0499 - val_loss: 6.4422\n",
      "Epoch 45/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0358 - val_loss: 6.4684\n",
      "Epoch 46/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0309 - val_loss: 6.4208\n",
      "Epoch 47/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0232 - val_loss: 6.4000\n",
      "Epoch 48/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0170 - val_loss: 6.4362\n",
      "Epoch 49/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0019 - val_loss: 6.4221\n",
      "Epoch 50/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9985 - val_loss: 6.4470\n",
      "Epoch 51/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9843 - val_loss: 6.3906\n",
      "Epoch 52/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9889 - val_loss: 6.4177\n",
      "Epoch 53/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9612 - val_loss: 6.5864\n",
      "Epoch 54/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9724 - val_loss: 6.4532\n",
      "Epoch 55/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9478 - val_loss: 6.6433\n",
      "Epoch 56/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9479 - val_loss: 6.3781\n",
      "Epoch 57/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.9370 - val_loss: 6.4138\n",
      "Epoch 58/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9278 - val_loss: 6.3746\n",
      "Epoch 59/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9262 - val_loss: 6.3301\n",
      "Epoch 60/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9194 - val_loss: 6.3466\n",
      "Epoch 61/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9137 - val_loss: 6.3982\n",
      "Epoch 62/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9042 - val_loss: 6.3760\n",
      "Epoch 63/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8953 - val_loss: 6.4942\n",
      "Epoch 64/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8891 - val_loss: 6.4774\n",
      "Epoch 65/200\n",
      "312/312 [==============================] - 0s 2ms/step - loss: 5.8894 - val_loss: 6.3620\n",
      "Epoch 66/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8805 - val_loss: 6.3824\n",
      "Epoch 67/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8751 - val_loss: 6.3283\n",
      "Epoch 68/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8661 - val_loss: 6.3395\n",
      "Epoch 69/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8669 - val_loss: 6.3724\n",
      "Epoch 70/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8623 - val_loss: 6.3464\n",
      "Epoch 71/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8579 - val_loss: 6.4598\n",
      "Epoch 72/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8528 - val_loss: 6.3404\n",
      "Epoch 73/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.8409 - val_loss: 6.3731\n",
      "Epoch 74/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.8480 - val_loss: 6.3769\n",
      "Epoch 75/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8258 - val_loss: 6.4594\n",
      "Epoch 76/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8401 - val_loss: 6.3828\n",
      "Epoch 77/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.8154 - val_loss: 6.3141\n",
      "Epoch 78/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8088 - val_loss: 6.3251\n",
      "Epoch 79/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.8108 - val_loss: 6.3049\n",
      "Epoch 80/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7988 - val_loss: 6.3418\n",
      "Epoch 81/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8000 - val_loss: 6.3433\n",
      "Epoch 82/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.8160 - val_loss: 6.2580\n",
      "Epoch 83/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.7937 - val_loss: 6.3021\n",
      "Epoch 84/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7749 - val_loss: 6.4294\n",
      "Epoch 85/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7855 - val_loss: 6.2816\n",
      "Epoch 86/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7768 - val_loss: 6.3519\n",
      "Epoch 87/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7649 - val_loss: 6.2557\n",
      "Epoch 88/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7584 - val_loss: 6.2795\n",
      "Epoch 89/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7598 - val_loss: 6.2709\n",
      "Epoch 90/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7528 - val_loss: 6.2486\n",
      "Epoch 91/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.7509 - val_loss: 6.3494\n",
      "Epoch 92/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7485 - val_loss: 6.2350\n",
      "Epoch 93/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7279 - val_loss: 6.2997\n",
      "Epoch 94/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7610 - val_loss: 6.2829\n",
      "Epoch 95/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7360 - val_loss: 6.2708\n",
      "Epoch 96/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7334 - val_loss: 6.2234\n",
      "Epoch 97/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7314 - val_loss: 6.2837\n",
      "Epoch 98/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7139 - val_loss: 6.3340\n",
      "Epoch 99/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7085 - val_loss: 6.2802\n",
      "Epoch 100/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.7092 - val_loss: 6.2359\n",
      "Epoch 101/200\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.6996 - val_loss: 6.2364\n",
      "Epoch 102/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.7065 - val_loss: 6.3152\n",
      "Epoch 103/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7161 - val_loss: 6.3791\n",
      "Epoch 104/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.7098 - val_loss: 6.2422\n",
      "Epoch 105/200\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.6957 - val_loss: 6.2595\n",
      "Epoch 106/200\n",
      "312/312 [==============================] - 0s 2ms/step - loss: 5.6925 - val_loss: 6.2709\n",
      "Epoch 107/200\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.6946 - val_loss: 6.3156\n",
      "Epoch 108/200\n",
      "212/312 [===================>..........] - ETA: 0s - loss: 5.5977"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32), y_train\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32), epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m          validation_data\u001b[39m=\u001b[39;49m(X_eval\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32), y_eval\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32)), shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values.astype(np.float32), y_train.values.astype(np.float32), epochs=200, batch_size=1024,\n",
    "         validation_data=(X_eval.values.astype(np.float32), y_eval.values.astype(np.float32)), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHHCAYAAABKudlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABi30lEQVR4nO3dd3gUZdvG4d9ueiEJJaQACb1XaVKkSKSIICICioiKYAFBBUQ+FYFXX0BRUUHsBBVRLCCogIAgVYpU6SAtQAg1IYWUzXx/zJuVSAvZkEngOo9jD7IzszP3ZmNyeT/PzNgMwzAQERERKaTsVhcgIiIi4gqFGRERESnUFGZERESkUFOYERERkUJNYUZEREQKNYUZERERKdQUZkRERKRQU5gRERGRQk1hRkRERAo1hRkRuW4efvhhypYtm6vXjho1CpvNlrcF5ZArdYtI/lOYEbkJ2Wy2HD2WLl1qdakiIldl072ZRG4+X375Zbbnn3/+OQsXLuSLL77ItvyOO+4gJCQk18dJT08nMzMTLy+va35tRkYGGRkZeHt75/r4ufXwww+zdOlSDhw4kO/HFpFr5251ASKS/x588MFsz//44w8WLlx40fJ/S05OxtfXN8fH8fDwyFV9AO7u7ri761eUiFydhplE5JJatWpFzZo1+fPPP2nRogW+vr783//9HwA//vgjHTt2JDw8HC8vLypUqMB//vMfHA5Htn38e+7JgQMHsNlsTJgwgY8++ogKFSrg5eVFw4YNWbduXbbXXmrOjM1mY+DAgcyePZuaNWvi5eVFjRo1mD9//kX1L126lAYNGuDt7U2FChX48MMPXZqHk5SUxJAhQyhTpgxeXl5UqVKFCRMm8O/m9sKFC2nevDlBQUH4+/tTpUoV5/cty3vvvUeNGjXw9fWlaNGiNGjQgK+++ipXdYmIOjMicgWnTp2iQ4cO9OzZkwcffNA55BQdHY2/vz/PPfcc/v7+/Pbbb4wcOZKEhATeeOONq+73q6++4ty5czz++OPYbDZef/11unbtyt9//33Vbs6KFSv44YcfeOqppyhSpAjvvvsu9957L4cOHaJ48eIAbNy4kfbt2xMWFsbo0aNxOByMGTOG4ODgXH0fDMOgc+fOLFmyhL59+1K3bl0WLFjAsGHDOHLkCG+//TYA27Zt46677qJ27dqMGTMGLy8v9u7dy8qVK537+vjjjxk0aBDdunVj8ODBnD9/ni1btrBmzRoeeOCBXNUnctMzROSmN2DAAOPfvw5atmxpAMYHH3xw0fbJyckXLXv88ccNX19f4/z5885lffr0MSIjI53P9+/fbwBG8eLFjdOnTzuX//jjjwZgzJ0717nslVdeuagmwPD09DT27t3rXLZ582YDMN577z3nsk6dOhm+vr7GkSNHnMv27NljuLu7X7TPS/l33bNnzzYA49VXX822Xbdu3Qybzeas5+233zYA48SJE5fd9913323UqFHjqjWISM5pmElELsvLy4tHHnnkouU+Pj7Or8+dO8fJkye57bbbSE5OZufOnVfdb48ePShatKjz+W233QbA33//fdXXRkVFUaFCBefz2rVrExAQ4Hytw+Fg0aJFdOnShfDwcOd2FStWpEOHDlfd/6X88ssvuLm5MWjQoGzLhwwZgmEYzJs3D4CgoCDAHIbLzMy85L6CgoKIiYm5aFhNRHJPYUZELqtUqVJ4enpetHzbtm3cc889BAYGEhAQQHBwsHPycHx8/FX3GxERke15VrA5c+bMNb826/VZr42LiyMlJYWKFStetN2lluXEwYMHCQ8Pp0iRItmWV6tWzbkezJDWrFkzHnvsMUJCQujZsyczZ87MFmyGDx+Ov78/jRo1olKlSgwYMCDbMJSIXDuFGRG5rAs7MFnOnj1Ly5Yt2bx5M2PGjGHu3LksXLiQ8ePHA1y2I3EhNze3Sy43cnClCFdee735+PiwbNkyFi1aRO/evdmyZQs9evTgjjvucE6OrlatGrt27eLrr7+mefPmfP/99zRv3pxXXnnF4upFCi+FGRG5JkuXLuXUqVNER0czePBg7rrrLqKiorING1mpZMmSeHt7s3fv3ovWXWpZTkRGRnL06FHOnTuXbXnWkFpkZKRzmd1up02bNrz11lts376d1157jd9++40lS5Y4t/Hz86NHjx5MnTqVQ4cO0bFjR1577TXOnz+fq/pEbnYKMyJyTbI6Ixd2QtLS0nj//fetKikbNzc3oqKimD17NkePHnUu37t3r3Nuy7W68847cTgcTJo0Kdvyt99+G5vN5pyLc/r06YteW7duXQBSU1MB8wyxC3l6elK9enUMwyA9PT1X9Ync7HRqtohck6ZNm1K0aFH69OnDoEGDsNlsfPHFFwVimCfLqFGj+PXXX2nWrBlPPvmkM4jUrFmTTZs2XfP+OnXqROvWrXnxxRc5cOAAderU4ddff+XHH3/kmWeecU5IHjNmDMuWLaNjx45ERkYSFxfH+++/T+nSpWnevDkAbdu2JTQ0lGbNmhESEsKOHTuYNGkSHTt2vGhOjojkjMKMiFyT4sWL89NPPzFkyBBeeuklihYtyoMPPkibNm1o166d1eUBUL9+febNm8fQoUN5+eWXKVOmDGPGjGHHjh05Otvq3+x2O3PmzGHkyJF88803TJ06lbJly/LGG28wZMgQ53adO3fmwIEDfPbZZ5w8eZISJUrQsmVLRo8eTWBgIACPP/4406dP56233iIxMZHSpUszaNAgXnrppTx7/yI3G92bSURuGl26dGHbtm3s2bPH6lJEJA9pzoyI3JBSUlKyPd+zZw+//PILrVq1sqYgEblu1JkRkRtSWFgYDz/8MOXLl+fgwYNMmTKF1NRUNm7cSKVKlawuT0TykObMiMgNqX379syYMYPY2Fi8vLxo0qQJ//3vfxVkRG5A6syIiIhIoaY5MyIiIlKoWRpmli1bRqdOnQgPD8dmszF79uyLttmxYwedO3cmMDAQPz8/GjZsyKFDh/K/WBERESmQLJ0zk5SURJ06dXj00Ufp2rXrRev37dtH8+bN6du3L6NHjyYgIIBt27bh7e2d42NkZmZy9OhRihQpgs1my8vyRURE5DoxDINz584RHh6O3X7l3kuBmTNjs9mYNWsWXbp0cS7r2bMnHh4efPHFF7neb0xMDGXKlMmDCkVERCS/HT58mNKlS19xmwJ7NlNmZiY///wzzz//PO3atWPjxo2UK1eOESNGZAs8/5aamuq8Bwr8c/+Yw4cPExAQcL3LFhERkTyQkJBAmTJlcnSbjwIbZuLi4khMTGTcuHG8+uqrjB8/nvnz59O1a1eWLFlCy5YtL/m6sWPHMnr06IuWBwQEKMyIiIgUMjmZIlJgh5mOHj1KqVKluP/++/nqq6+c23Xu3Bk/Pz9mzJhxyf38uzOTlezi4+MVZkRERAqJhIQEAgMDc/T3u8B2ZkqUKIG7uzvVq1fPtrxatWqsWLHisq/z8vLCy8vrepcnIiIiBUSBvc6Mp6cnDRs2ZNeuXdmW7969m8jISIuqEhERkYLG0s5MYmIie/fudT7fv38/mzZtolixYkRERDBs2DB69OhBixYtaN26NfPnz2fu3LksXbrUuqJFRG5yDoeD9PR0q8uQQs7DwwM3N7c82Zelc2aWLl1K69atL1rep08foqOjAfjss88YO3YsMTExVKlShdGjR3P33Xfn+BjXMuYmIiKXZxgGsbGxnD171upS5AYRFBREaGjoJSf5Xsvf7wIzAfh6UZgREckbx44d4+zZs5QsWRJfX19diFRyzTAMkpOTiYuLIygoiLCwsIu2uSEmAIuISMHhcDicQaZ48eJWlyM3AB8fH8C8FEvJkiVdGnIqsBOARUSk4MiaI+Pr62txJXIjyfp5cnUOlsKMiIjkmIaWJC/l1c+TwoyIiIgUagozIiIi16hs2bJMnDgxx9svXboUm8123c8Ei46OJigo6LoeoyBSmBERkRuWzWa74mPUqFG52u+6devo379/jrdv2rQpx44dIzAwMFfHkyvT2Uy5lJAAZ86Ary8EB1tdjYiIXMqxY8ecX3/zzTeMHDky25Xl/f39nV8bhoHD4cDd/ep/GoOv8Re/p6cnoaGh1/QayTl1ZnJp0iQoWxb+7/+srkRERC4nNDTU+QgMDMRmszmf79y5kyJFijBv3jzq16+Pl5cXK1asYN++fdx9992EhITg7+9Pw4YNWbRoUbb9/nuYyWaz8cknn3DPPffg6+tLpUqVmDNnjnP9v4eZsoaDFixYQLVq1fD396d9+/bZwldGRgaDBg0iKCiI4sWLM3z4cPr06eO8IXNOTZkyhQoVKuDp6UmVKlX44osvnOsMw2DUqFFERETg5eVFeHg4gwYNcq5///33qVSpEt7e3oSEhNCtW7drOnZ+UZjJpazgnpFhbR0iIlYxDEhKsuaRl5d7feGFFxg3bhw7duygdu3aJCYmcuedd7J48WI2btxI+/bt6dSpE4cOHbrifkaPHk337t3ZsmULd955J7169eL06dOX3T45OZkJEybwxRdfsGzZMg4dOsTQoUOd68ePH8/06dOZOnUqK1euJCEhgdmzZ1/Te5s1axaDBw9myJAh/PXXXzz++OM88sgjLFmyBIDvv/+et99+mw8//JA9e/Ywe/ZsatWqBcD69esZNGgQY8aMYdeuXcyfP58WLVpc0/HzjXGDi4+PNwAjPj4+T/f75puGAYbx4IN5ulsRkQIpJSXF2L59u5GSkuJclpho/h604pGYeO3vYerUqUZgYKDz+ZIlSwzAmD179lVfW6NGDeO9995zPo+MjDTefvtt53PAeOmlly743iQagDFv3rxsxzpz5oyzFsDYu3ev8zWTJ082QkJCnM9DQkKMN954w/k8IyPDiIiIMO6+++4cv8emTZsa/fr1y7bNfffdZ9x5552GYRjGm2++aVSuXNlIS0u7aF/ff/+9ERAQYCQkJFz2eK661M9Vlmv5+63OTC6pMyMicmNo0KBBtueJiYkMHTqUatWqERQUhL+/Pzt27LhqZ6Z27drOr/38/AgICCAuLu6y2/v6+lKhQgXn87CwMOf28fHxHD9+nEaNGjnXu7m5Ub9+/Wt6bzt27KBZs2bZljVr1owdO3YAcN9995GSkkL58uXp168fs2bNIuN/f9juuOMOIiMjKV++PL1792b69OkkJydf0/Hzi8JMLinMiMjNztcXEhOteeTlhYj9/PyyPR86dCizZs3iv//9L8uXL2fTpk3UqlWLtLS0K+7Hw8Mj23ObzUZmZuY1bW/k8+0Sy5Qpw65du3j//ffx8fHhqaeeokWLFqSnp1OkSBE2bNjAjBkzCAsLY+TIkdSpU6dA3mhUYSaXFGZE5GZns4GfnzWP63kh4pUrV/Lwww9zzz33UKtWLUJDQzlw4MD1O+AlBAYGEhISwrp165zLHA4HGzZsuKb9VKtWjZUrV2ZbtnLlSqpXr+587uPjQ6dOnXj33XdZunQpq1evZuvWrQC4u7sTFRXF66+/zpYtWzhw4AC//fabC+/s+tCp2bmkMCMicmOqVKkSP/zwA506dcJms/Hyyy9fscNyvTz99NOMHTuWihUrUrVqVd577z3OnDlzTbcAGDZsGN27d6devXpERUUxd+5cfvjhB+fZWdHR0TgcDho3boyvry9ffvklPj4+REZG8tNPP/H333/TokULihYtyi+//EJmZiZVqlS5Xm851xRmcklhRkTkxvTWW2/x6KOP0rRpU0qUKMHw4cNJSEjI9zqGDx9ObGwsDz30EG5ubvTv35927dpd092lu3TpwjvvvMOECRMYPHgw5cqVY+rUqbRq1QqAoKAgxo0bx3PPPYfD4aBWrVrMnTuX4sWLExQUxA8//MCoUaM4f/48lSpVYsaMGdSoUeM6vePcsxn5PUCXzxISEggMDCQ+Pp6AgIA82+/06fDggxAVBQsX5tluRUQKpPPnz7N//37KlSuHt7e31eXclDIzM6lWrRrdu3fnP//5j9Xl5Ikr/Vxdy99vdWZySZ0ZERG5ng4ePMivv/5Ky5YtSU1NZdKkSezfv58HHnjA6tIKHE0AziWFGRERuZ7sdjvR0dE0bNiQZs2asXXrVhYtWkS1atWsLq3AUWcmlxRmRETkeipTpsxFZyLJpakzk0tZYcbhsLYOERGRm53CTC6pMyMiIlIwKMzkksKMiIhIwaAwk0sKMyIiIgWDwkwuKcyIiIgUDDqbKZfOZByF0odI8QkGKlx1exEREbk+1JnJpfmx0+CxJpypMdbqUkRE5Dpr1aoVzzzzjPN52bJlmThx4hVfY7PZmD17tsvHzqv9XMmoUaOoW7fudT3G9aQwk0vudvNbl2nk/83HREQkZzp16kT79u0vuW758uXYbDa2bNlyzftdt24d/fv3d7W8bC4XKI4dO0aHDh3y9Fg3GoWZXHJzU5gRESno+vbty8KFC4mJiblo3dSpU2nQoAG1a9e+5v0GBwfj6+ubFyVeVWhoKF5eXvlyrMJKYSaX3P8XZgwUZkRECqq77rqL4OBgoqOjsy1PTEzk22+/pW/fvpw6dYr777+fUqVK4evrS61atZgxY8YV9/vvYaY9e/bQokULvL29qV69OgsvcQfi4cOHU7lyZXx9fSlfvjwvv/wy6enpAERHRzN69Gg2b96MzWbDZrM5a/73MNPWrVu5/fbb8fHxoXjx4vTv35/ExETn+ocffpguXbowYcIEwsLCKF68OAMGDHAeKycyMzMZM2YMpUuXxsvLi7p16zJ//nzn+rS0NAYOHEhYWBje3t5ERkYydqw57cIwDEaNGkVERAReXl6Eh4czaNCgHB87NzQBOJfc1ZkRkZucYRgkpydbcmxfD19sNttVt3N3d+ehhx4iOjqaF1980fmab7/9FofDwf33309iYiL169dn+PDhBAQE8PPPP9O7d28qVKhAo0aNrnqMzMxMunbtSkhICGvWrCE+Pj7b/JosRYoUITo6mvDwcLZu3Uq/fv0oUqQIzz//PD169OCvv/5i/vz5LFq0CIDAwMCL9pGUlES7du1o0qQJ69atIy4ujscee4yBAwdmC2xLliwhLCyMJUuWsHfvXnr06EHdunXp16/fVd8PwDvvvMObb77Jhx9+SL169fjss8/o3Lkz27Zto1KlSrz77rvMmTOHmTNnEhERweHDhzl8+DAA33//PW+//TZff/01NWrUIDY2ls2bN+fouLmlMJNL6syIyM0uOT0Z/7H+lhw7cUQifp5+Odr20Ucf5Y033uD333+nVatWgDnEdO+99xIYGEhgYCBDhw51bv/000+zYMECZs6cmaMws2jRInbu3MmCBQsIDw8H4L///e9F81xeeukl59dly5Zl6NChfP311zz//PP4+Pjg7++Pu7s7oaGhlz3WV199xfnz5/n888/x8zPf/6RJk+jUqRPjx48nJCQEgKJFizJp0iTc3NyoWrUqHTt2ZPHixTkOMxMmTGD48OH07NkTgPHjx7NkyRImTpzI5MmTOXToEJUqVaJ58+bYbDYiIyOdrz106BChoaFERUXh4eFBREREjr6PrtAwUy6pMyMiUjhUrVqVpk2b8tlnnwGwd+9eli9fTt++fQFwOBz85z//oVatWhQrVgx/f38WLFjAoUOHcrT/HTt2UKZMGWeQAWjSpMlF233zzTc0a9aM0NBQ/P39eemll3J8jAuPVadOHWeQAWjWrBmZmZns2rXLuaxGjRq4ubk5n4eFhREXF5ejYyQkJHD06FGaNWuWbXmzZs3YsWMHYA5lbdq0iSpVqjBo0CB+/fVX53b33XcfKSkplC9fnn79+jFr1iwyrvNF2dSZySV1ZkTkZufr4UviiMSrb3idjn0t+vbty9NPP83kyZOZOnUqFSpUoGXLlgC88cYbvPPOO0ycOJFatWrh5+fHM888Q1paWp7Vu3r1anr16sXo0aNp164dgYGBfP3117z55pt5dowLeXh4ZHtus9nIzMy7v1e33HIL+/fvZ968eSxatIju3bsTFRXFd999R5kyZdi1axeLFi1i4cKFPPXUU87O2L/ryisKM7mUFWawOcjMBLt6XCJyk7HZbDke6rFa9+7dGTx4MF999RWff/45Tz75pHP+zMqVK7n77rt58MEHAXMOzO7du6levXqO9l2tWjUOHz7MsWPHCAsLA+CPP/7Its2qVauIjIzkxRdfdC47ePBgtm08PT1xOBxXPVZ0dDRJSUnO7szKlSux2+1UqVIlR/VeTUBAAOHh4axcudIZ+LKOc+FwUUBAAD169KBHjx5069aN9u3bc/r0aYoVK4aPjw+dOnWiU6dODBgwgKpVq7J161ZuueWWPKnx3xRmcsnDGWYyycgAT09r6xERkcvz9/enR48ejBgxgoSEBB5++GHnukqVKvHdd9+xatUqihYtyltvvcXx48dzHGaioqKoXLkyffr04Y033iAhISFbaMk6xqFDh/j6669p2LAhP//8M7Nmzcq2TdmyZdm/fz+bNm2idOnSFClS5KJTsnv16sUrr7xCnz59GDVqFCdOnODpp5+md+/ezvkyeWHYsGG88sorVKhQgbp16zJ16lQ2bdrE9OnTAXjrrbcICwujXr162O12vv32W0JDQwkKCiI6OhqHw0Hjxo3x9fXlyy+/xMfHJ9u8mrymfkIuuWeNRf4vzIiISMHWt29fzpw5Q7t27bLNb3nppZe45ZZbaNeuHa1atSI0NJQuXbrkeL92u51Zs2aRkpJCo0aNeOyxx3jttdeybdO5c2eeffZZBg4cSN26dVm1ahUvv/xytm3uvfde2rdvT+vWrQkODr7k6eG+vr4sWLCA06dP07BhQ7p160abNm2YNGnStX0zrmLQoEE899xzDBkyhFq1ajF//nzmzJlDpUqVAPPMrNdff50GDRrQsGFDDhw4wC+//ILdbicoKIiPP/6YZs2aUbt2bRYtWsTcuXMpXrx4ntZ4IZthGMZ123sBkJCQQGBgIPHx8QQEBOTZfj9c+xlPzOsLu+4i/oO55OGuRUQKnPPnz7N//37KlSuHt7e31eXIDeJKP1fX8vdbnZlccv/XMJOIiIhYQ2EmlxRmRERECgaFmVxys/8TZq4y+VxERESuI4WZXLLb1JkREREpCBRmcklhRkRuRjf4OSOSz/Lq50lhJpcUZkTkZpJ15dbkZGtuLCk3pqyfJ1evDKyL5uWSwoyI3Ezc3NwICgpy3t/H1zdnd60WuRTDMEhOTiYuLo6goKBs95HKDYWZXFKYEZGbTdbdnHN6w0KRqwkKCrriXcJzSmEmlxRmRORmY7PZCAsLo2TJkqSnp1tdjhRyHh4eLndksijM5JLCjIjcrNzc3PLsj5BIXtAE4FxSmBERESkYFGZySWFGRESkYFCYySVnmLE7FGZEREQspDCTS+rMiIiIFAwKM7nkZvvf5DeFGREREUspzOSSOjMiIiIFg8JMLinMiIiIFAwKM7mkMCMiIlIwKMzkksKMiIhIwaAwk0sKMyIiIgWDpWFm2bJldOrUifDwcGw2G7Nnz77stk888QQ2m42JEyfmW31XojAjIiJSMFgaZpKSkqhTpw6TJ0++4nazZs3ijz/+IDw8PJ8quzqFGRERkYLB0htNdujQgQ4dOlxxmyNHjvD000+zYMECOnbsmE+VXd2FYcbhsLYWERGRm1mBvmt2ZmYmvXv3ZtiwYdSoUSNHr0lNTSU1NdX5PCEh4brUps6MiIhIwVCgJwCPHz8ed3d3Bg0alOPXjB07lsDAQOejTJky16U2hRkREZGCocCGmT///JN33nmH6OhobDZbjl83YsQI4uPjnY/Dhw9fl/oUZkRERAqGAhtmli9fTlxcHBEREbi7u+Pu7s7BgwcZMmQIZcuWvezrvLy8CAgIyPa4HhRmRERECoYCO2emd+/eREVFZVvWrl07evfuzSOPPGJRVf9QmBERESkYLA0ziYmJ7N271/l8//79bNq0iWLFihEREUHx4sWzbe/h4UFoaChVqlTJ71IvojAjIiJSMFgaZtavX0/r1q2dz5977jkA+vTpQ3R0tEVV5cw/YcahMCMiImIhS8NMq1atMAwjx9sfOHDg+hVzjdSZERERKRgK7ATggs7N7mZ+oTAjIiJiKYWZXFJnRkREpGBQmMklhRkREZGCQWEmlxRmRERECgaFmVxSmBERESkYFGZyyRlm7AozIiIiVlKYySVnmAHSM3J+ermIiIjkLYWZXMoeZjItrEREROTmpjCTSxeGmQyFGREREcsozORSts6MQ2FGRETEKgozuaTOjIiISMGgMJNL6syIiIgUDAozuXRhmHFkKsyIiIhYRWEmlzTMJCIiUjAozORS9mEmh4WViIiI3NwUZnIpW2dGc2ZEREQsozCTSwozIiIiBYPCjAvs//v2KcyIiIhYR2HGBTabwoyIiIjVFGZcoM6MiIiI9RRmXKDOjIiIiPUUZlyQNQk4QxfNExERsYzCjAuyhpkc6syIiIhYRmHGBXYNM4mIiFhOYcYFWWFG92YSERGxjsKMC9SZERERsZ7CjAvUmREREbGewowL1JkRERGxnsKMC9SZERERsZ7CjAsuDDOGYXExIiIiNymFGRfY7f/79tkcqDkjIiJiDYUZF2R1ZrBlkpFhbS0iIiI3K4UZF7hdEGYcDmtrERERuVkpzLjAze5mfqHOjIiIiGUUZlzgZtcwk4iIiNUUZlygOTMiIiLWU5hxgcKMiIiI9RRmXKAwIyIiYj2FGRcozIiIiFhPYcYFCjMiIiLWU5hxgcKMiIiI9RRmXKAwIyIiYj2FGRcozIiIiFhPYcYFCjMiIiLWU5hxgcKMiIiI9RRmXKAwIyIiYj2FGRcozIiIiFhPYcYFzjBjdyjMiIiIWERhxgXqzIiIiFhPYcYFbnY38wuFGREREcsozLhAnRkRERHrKcy4QGFGRETEegozLrgwzDgc1tYiIiJys1KYcYE6MyIiItZTmHGBwoyIiIj1FGZcoDAjIiJiPUvDzLJly+jUqRPh4eHYbDZmz57tXJeens7w4cOpVasWfn5+hIeH89BDD3H06FHrCv4XhRkRERHrWRpmkpKSqFOnDpMnT75oXXJyMhs2bODll19mw4YN/PDDD+zatYvOnTtbUOmlKcyIiIhYz93Kg3fo0IEOHTpccl1gYCALFy7MtmzSpEk0atSIQ4cOERERkR8lXpHCjIiIiPUsDTPXKj4+HpvNRlBQ0GW3SU1NJTU11fk8ISHhutWjMCMiImK9QjMB+Pz58wwfPpz777+fgICAy243duxYAgMDnY8yZcpct5oUZkRERKxXKMJMeno63bt3xzAMpkyZcsVtR4wYQXx8vPNx+PDh61aXwoyIiIj1CvwwU1aQOXjwIL/99tsVuzIAXl5eeHl55UttCjMiIiLWK9BhJivI7NmzhyVLllC8eHGrS8rmnzDjUJgRERGxiKVhJjExkb179zqf79+/n02bNlGsWDHCwsLo1q0bGzZs4KeffsLhcBAbGwtAsWLF8PT0tKpsJzvqzIiIiFjN0jCzfv16Wrdu7Xz+3HPPAdCnTx9GjRrFnDlzAKhbt2621y1ZsoRWrVrlV5mXpWEmERER61kaZlq1aoVhGJddf6V1BYGb3c38QmFGRETEMoXibKaCSp0ZERER6ynMuEBhRkRExHoKMy5QmBEREbGewowLFGZERESspzDjAoUZERER6ynMuEBhRkRExHoKMy5QmBEREbGewowLLgwzDoe1tYiIiNysFGZcoM6MiIiI9RRmXKAwIyIiYj2FGRdomElERMR6CjMuUGdGRETEegozLnCGGbtDYUZERMQiCjMu0DCTiIiI9RRmXKBhJhEREespzLjAzeZmfqEwIyIiYhmFGRdomElERMR6CjMu0DCTiIiI9RRmXKAwIyIiYj2FGRdomElERMR6CjMuUGdGRETEegozLlCYERERsZ7CjAs0zCQiImI9hRkXqDMjIiJiPYUZFyjMiIiIWE9hxgUaZhIREbGewowL1JkRERGxnsKMCxRmRERErKcw44J/woxDw0wiIiIWyVWYOXz4MDExMc7na9eu5ZlnnuGjjz7Ks8IKgws7M5mZkJlpbT0iIiI3o1yFmQceeIAlS5YAEBsbyx133MHatWt58cUXGTNmTJ4WWJBdGGYAdWdEREQskKsw89dff9GoUSMAZs6cSc2aNVm1ahXTp08nOjo6L+sr0BRmRERErJerMJOeno6XlxcAixYtonPnzgBUrVqVY8eO5V11BZyb3c384n9hRpOARURE8l+uwkyNGjX44IMPWL58OQsXLqR9+/YAHD16lOLFi+dpgQXZvzszCjMiIiL5L1dhZvz48Xz44Ye0atWK+++/nzp16gAwZ84c5/DTzUDDTCIiItZzz82LWrVqxcmTJ0lISKBo0aLO5f3798fX1zfPiivo1JkRERGxXq46MykpKaSmpjqDzMGDB5k4cSK7du2iZMmSeVpgQeYMM3aFGREREavkKszcfffdfP755wCcPXuWxo0b8+abb9KlSxemTJmSpwUWZFlhxmbXMJOIiIhVchVmNmzYwG233QbAd999R0hICAcPHuTzzz/n3XffzdMCCzJnmNEwk4iIiGVyFWaSk5MpUqQIAL/++itdu3bFbrdz6623cvDgwTwtsCDTMJOIiIj1chVmKlasyOzZszl8+DALFiygbdu2AMTFxREQEJCnBRZkGmYSERGxXq7CzMiRIxk6dChly5alUaNGNGnSBDC7NPXq1cvTAgsyDTOJiIhYL1enZnfr1o3mzZtz7Ngx5zVmANq0acM999yTZ8UVdDo1W0RExHq5CjMAoaGhhIaGOu+eXbp06Zvqgnlw8ZwZDTOJiIjkv1wNM2VmZjJmzBgCAwOJjIwkMjKSoKAg/vOf/5CZmZnXNRZYGmYSERGxXq46My+++CKffvop48aNo1mzZgCsWLGCUaNGcf78eV577bU8LbKg+qczY7ZkFGZERETyX67CzLRp0/jkk0+cd8sGqF27NqVKleKpp566+cKM7s0kIiJimVwNM50+fZqqVatetLxq1aqcPn3a5aIKC00AFhERsV6uwkydOnWYNGnSRcsnTZpE7dq1XS6qsHCzuZlfKMyIiIhYJlfDTK+//jodO3Zk0aJFzmvMrF69msOHD/PLL7/kaYEFmTozIiIi1stVZ6Zly5bs3r2be+65h7Nnz3L27Fm6du3Ktm3b+OKLL/K6xgJLc2ZERESsl+vrzISHh1800Xfz5s18+umnfPTRRy4XVhioMyMiImK9XHVmxKQwIyIiYj2FGRdomElERMR6CjMuyAozBurMiIiIWOWa5sx07dr1iuvPnj3rSi2FjoaZRERErHdNnZnAwMArPiIjI3nooYdyvL9ly5bRqVMnwsPDsdlszJ49O9t6wzAYOXIkYWFh+Pj4EBUVxZ49e66l5OtKw0wiIiLWu6bOzNSpU/P04ElJSdSpU4dHH330kl2f119/nXfffZdp06ZRrlw5Xn75Zdq1a8f27dvx9vbO01pyQ8NMIiIi1sv1qdl5oUOHDnTo0OGS6wzDYOLEibz00kvcfffdAHz++eeEhIQwe/ZsevbsmZ+lXpKGmURERKxXYCcA79+/n9jYWKKiopzLAgMDady4MatXr7awsn/8uzOjYSYREZH8Z2ln5kpiY2MBCAkJybY8JCTEue5SUlNTSU1NdT5PSEi4PgWizoyIiEhBUGA7M7k1duzYbJOSy5Qpc92O9U9nxmzJKMyIiIjkvwIbZkJDQwE4fvx4tuXHjx93rruUESNGEB8f73wcPnz4utXoDDM6m0lERMQyBTbMlCtXjtDQUBYvXuxclpCQwJo1a5x36r4ULy8vAgICsj2uF+cwEwCGOjMiIiIWsHTOTGJiInv37nU+379/P5s2baJYsWJERETwzDPP8Oqrr1KpUiXnqdnh4eF06dLFuqIvkC3M2DLJyHCzrhgREZGblKVhZv369bRu3dr5/LnnngOgT58+REdH8/zzz5OUlET//v05e/YszZs3Z/78+QXiGjMAbvYLwostE4dDYUZERCS/WRpmWrVqhWEYl11vs9kYM2YMY8aMyceqcu7izox1tYiIiNysCuycmcJAYUZERMR6CjMu+HeY0dlMIiIi+U9hxgXqzIiIiFhPYcYFCjMiIiLWU5hxgYaZRERErKcw4wJ1ZkRERKynMOMCG7YLnijMiIiIWEFhxgU2m+2fQKNhJhEREUsozLjIOdSkzoyIiIglFGZcpDAjIiJiLYUZFznDjN2hYSYRERELKMy4SJ0ZERERaynMuEhhRkRExFoKMy66MMxomElERCT/Kcy4yM3uZn6hzoyIiIglFGZcpGEmERERaynMuEjDTCIiItZSmHGROjMiIiLWUphxkcKMiIiItRRmXKRhJhEREWspzLhInRkRERFrKcy4SGFGRETEWgozLtIwk4iIiLUUZlykzoyIiIi1FGZcpDAjIiJiLYUZF2mYSURExFoKMy76J8w41JkRERGxgMKMizTMJCIiYi2FGRcpzIiIiFhLYcZFmjMjIiJiLYUZF7nZ3Mwv1JkRERGxhMKMizTMJCIiYi2FGRddGGYAMjMtLEZEROQmpDDjon+HGXVnRERE8pfCjIsUZkRERKylMOOif4cZndEkIiKSvxRmXKTOjIiIiLUUZlykMCMiImIthRkXOcOMXcNMIiIiVlCYcVFWmHFzU2dGRETECgozLsoKM3Z3hRkRERErKMy4yBlm3DTMJCIiYgWFGRdpmElERMRaCjMu+meYyWzJKMyIiIjkL4UZF2WFGZuGmURERCyhMOMiDTOJiIhYS2HGRf+eAKwwIyIikr8UZlzkZncDNMwkIiJiFYUZF6kzIyIiYi2FGRcpzIiIiFhLYcZFzjCjezOJiIhYQmHGRerMiIiIWEthxkX/vs6MwoyIiEj+UphxkYaZRERErKUw4yL7/76FNrs6MyIiIlZQmHGR5syIiIhYS2HGRc45MxpmEhERsUSBDjMOh4OXX36ZcuXK4ePjQ4UKFfjPf/6DYRhWl+akCcAiIiLWcre6gCsZP348U6ZMYdq0adSoUYP169fzyCOPEBgYyKBBg6wuD7h4ArDCjIiISP4q0GFm1apV3H333XTs2BGAsmXLMmPGDNauXWtxZf/4Z5jJHF/SMJOIiEj+KtDDTE2bNmXx4sXs3r0bgM2bN7NixQo6dOhw2dekpqaSkJCQ7XE9/XvOjDozIiIi+atAd2ZeeOEFEhISqFq1Km5ubjgcDl577TV69ep12deMHTuW0aNH51uNmjMjIiJirQLdmZk5cybTp0/nq6++YsOGDUybNo0JEyYwbdq0y75mxIgRxMfHOx+HDx++rjU6w4xNZzOJiIhYoUB3ZoYNG8YLL7xAz549AahVqxYHDx5k7Nix9OnT55Kv8fLywsvLK99qdLO7AerMiIiIWKVAd2aSk5Ox27OX6ObmRmZmpkUVXUxzZkRERKxVoDsznTp14rXXXiMiIoIaNWqwceNG3nrrLR599FGrS3PSRfNERESsVaDDzHvvvcfLL7/MU089RVxcHOHh4Tz++OOMHDnS6tKcssIMNnVmRERErFCgw0yRIkWYOHEiEydOtLqUy9Iwk4iIiLUK9JyZwkDDTCIiItZSmHHRv0/NVmdGREQkfynMuMg5Z0bDTCIiIpZQmHGRhplERESspTDjIp3NJCIiYi2FGRdpzoyIiIi1FGZcpDkzIiIi1lKYcdE/w0zmZBnNmREREclfCjMu0pwZERERaynMuEhhRkRExFoKMy76d5jRMJOIiEj+UphxkaebJwDptiRAnRkREZH8pjDjomolqgFwNOMvQGFGREQkvynMuKh2SG0ATjsOgc9pDTOJiIjkM4UZFwV6B1IuqJz5JGQL589bW4+IiMjNRmEmD9QNrWt+EbqJtWshJcXSckRERG4qCjN5ICvM+FXYRFISLFhgbT0iIiI3E4WZPFAnpA4APuU3AfD99xYWIyIicpNRmMkDWZ2Zs+7bwS2NuXMhNdXamkRERG4WCjN5ICIwgiDvIDKMdIpX3UF8PCxebHVVIiIiNweFmTxgs9mc3Zk67TYBMHOmdfWIiIjcTBRm8kjdkLoAFK+xCYAvvoA1a6yrR0RE5GahMJNH6oXVA2D7+YU80MsgMxP69NFp2iIiItebwkwe6VS5E34efmw7sY1uwxYTFga7dsGLL1pdmYiIyI1NYSaPFPUpyqP1HgXg47/e4pNPzOUTJ8KyZdbVJSIicqNTmMlDgxsPxoaNeXvnUbbhdvr2BcOAhx+GxESrqxMREbkxKczkoQrFKtClahcA3lz1Jm+9BRERsH8/PPustbWJiIjcqBRm8tjQpkMBiN4czcGUrUydai7/5BN4+20LCxMREblBKczksaZlmnJvtXvJNDIZPH8wrVsbvP66ue6553T9GRERkbymMHMdTGg7AS83L5YcWMKMv2YwdCgMHGiu69ULpk2ztj4REZEbicLMdVA2qCzDmg4DoNcPvaj/0S20eWoOvXtDRoY5IXjECDhxwto6RUREbgQKM9fJiNtG8GDtB/Gwe7AxdiPdv+vGCxN2Mny4uX7cOChdGh55BOLirK1VRESkMFOYuU58PXz54p4vODbkGG0rtCU9M50B855k7FiDr7+GBg0gLQ2io6F6dfjsM10tWEREJDcUZq6z4r7F+aDjB/i4+7D0wFK+3PIlPXrAunWwahXUqQOnTkHfvhAaCk89BbGxV97nDzt+IHRCKMsO6mp8IiIiCjP5oFzRcrzc4mUAnlnwDHtO7QGgSRMz1Lz+unk9moQEmDIFKleGCRPg3LlL7+/1la9zPOk40Zui8+kdiIiIFFwKM/lkSNMhNCrViNMpp+kwvQMnkszZvx4eMGyYeWG9RYvM4adz58xl4eHQvz98990/k4WPnTvGmiPm7bjXHllr1dsREREpMBRm8omnmydzes6hbFBZ9p3ZR4voFry35j2OJx4HwG6HNm1gzRrzAntVqpi3QPj4Y7jvPnMIqkcPeG/hXOc+t5/YzrnUy7RvREREbhI2wzAMq4u4nhISEggMDCQ+Pp6AgACry2HHiR3cNvU2TqWcci6rH1af9hXb075ie24tfSvudncMA5YsgR9+MG9UuXXr/zZ+oCNU/sX52imNltK/XUvsdjAMgz9i/qBWSC38Pf3z+Z2JiIjknWv5+60wY4ETSSf4autXfPXXVxcNFQX7BjOs6TAGNBqAr4evc/mWLfDaG4nMLFsC3FMhrjqU3A6/vk6lE8MYOBDO1/iQ4Sue4LF6j/Fx54/z+22JiIjkGYWZCxTEMHOh44nH+XXfr8zfN58Fexc4OzbhRcKZ12setUNqO7f9fvv3dPu2G6V8KlA7vR/zMl7Afdd9ZMyYCW5pMKgCBMbglRHMMFsszZraadUKvL0tenMiIiK5dC1/vzVnxmIh/iH0rtOb6V2nEzs0lql3T6VsUFmOnjvKHV/cwa6TuwDYfWo3IxaPAKBHnbsZ9kAjAMIbrmXyZIjs9CUExgCQ6n6CVz/6iw4doEQJ6NrVvI7N8ePWvEcREZHrSZ2ZAujs+bO0ntaaTbGbCPYNpmGphqw6vIqz588SERjB8keWE+QdRNC4IAwMjj53lJbRLdlzeg/uNk8yjDQann6LmG+f5dix7Ptu1AgaN4ZSpcyL9bVoAYGB1rxPERGRy9Ew0wUKY5gBc15Ny+iW7Di5w7msaZmm/ND9B0L8QwCoPrk6O07uoHZIbbYc30Ixn2IMbjyYV5a+wp2V7mRuz5/ZuBF++gnmzoU//7z4OHY7VKwIISHmGVR33QX165unh3t5QblyYLPl17sWERExKcxcoLCGGYDk9GQW/72YE8kn8HLzolv1bni5eznXPzz7YaZt/ucW3FM6TuHW0rdS78N6+Hv6c/r503i4eTjXHz0K8+fDnj0QEwNr18Lu3f9bWe0H8EyEzQ9lq6FUKbj9dvPRqhVERirciIjI9acwc4HCHGauZv3R9Tzx0xM0LdOUJxs8SbXgamQamYRMCOFk8klWPLKCZhHNrriPI0dg1V+H6fFHWQwyCZu7nrhN9QkMNK9zk5aWffugIKhRw7xicUQEVK1qPkqVgpIlwd3dDDt2zcYSEREXXMvfb/d8qkmugwbhDVjff322ZXabndZlW/Pt9m/5ZOMnFPUpSrUS1bBdpp1SqhRs3/MZBpkAtH95Mp92/gybzbzx5apV8Ntv5mP9ejh7FlauNB+XY7NBs2bmxGMwO0JVq0KHDuZVjUVERPKSOjM3oI///Jj+P/V3Pr+93O380P0HvNy9+HD9h5QvWp5OVToB4Mh0UO6dchxOOAyAt7s3Mc/GUNy3+EX7TUuDHTvMx5EjcOCA+fWuXebNMTMyrl5bmTLm3Jysh7e3OT/Hx8cMVlmPkiXV3RERuZlpmOkCN2OYSU5PZuSSkayOWc2fR/8k1ZFKnZA6pDpS2XlyJwADGw7kzXZvsvjvxdz51Z0U9S5K6YDSbI3byutRrzOs2bBrOmZmJsTH//PvnDmwcCH4+5uTi9euNR85/Wlzdze7OFnhpkIF88acjRqZt3bQvB0RkRubwswFbsYwc6GNxzbSfnp74pLiACjmU4zTKacBKF+0PB52D3ad2sXgxoOpVbIWj819jLJBZdnyxBaKeBXJ01rOnPmnk5P1cDigSBFITja7PTExZpfnSj+VXl7m9XPOn4f0dLOrU7SoOUG5XTuzq+PjY3Z9/PzMMOTmlqdvRURErjOFmQvc7GEGYM+pPfSb24/KxSszLmocqw6voves3pw9f9a5zV9P/kW5ouWIeDuCUymnqFC0Ah/e9SGlAkpht9lxs7lR3Lc4Qd5BOTpmTEIMv+77lVvCbqFuaN1rqjcjwww0MTH/BJxt28x5Ojt25Ly7k8XXF2rVgrJlza5OWFj2f8uXNztIIiJScCjMXEBh5tISUhNY9PciFv+9mMrFKzP41sEArIlZQ/fvunMo/tBFr/GwezAuahzP3vrsZScUHz13lGcXPMv327/HYTgAaFOuDRPbT6RmyZou152WZk4oPnXK7Lx4eJgTlQ8dgnnzzAnLiYnmsvPnzfk46elX329EBNxyCzRvboafffvMDs8jj0BwsMtli4gUattPbGfB3gUMbDQw2yU/rieFmQsozFy70ymnGTRvEAv2LcCR6cBhOMjIzCA5PRmAO8rfwYnkE8QkxND/lv682OJFfD18iU2MpWV0S3afMi9eU6tkLbaf2I7DcBAZGMn2Aduz3TwzPzgcsHeveaPOo0fh2DHzERtr/psVjC7H2xtq1oT9+81QVK2aeeXk6tWhdGlISDDnCVWoAJUrmxOcNXFZRG40UZ9HsXj/YmbcO4OeNXvmyzEVZi6gMJM3DMPg3TXvMuTXIc6OS5YyAWVoXa41a4+sZefJnUQERjC7x2zqhdXj4NmD3Db1Ng4nHOblFi8zpvUY5/62xm0l2DeYsCJhVrwlp9OnzWGsP/4wh7IcDjOcrFxpno5+Lby8zCsqV65sTmD++2/zrK9y5aBuXbj3XrMDJCJSWBiGQfAbwZxKOcULzV5gbNTYfDmuwswFFGby1vKDy/l+x/c0LtUYN7sbwxYOyzYkVapIKX5/+HcqFKvgXJZ1t28vNy++ve9bYhNj+XjDx6w7ug5fD19eu/01nm70NG72gjVL1zDMM7BiYsyA4uZmztnZvt18HD/+z32t9u41H/++yOClNGhgztdJSDD/rV7dPNbJk2aXx9vbnMfTsqXZCVKnR0SsFJcUR8gE8zY6nSp3Ys79c/LluAozF1CYub6S0pL4Zc8v7D29l6T0JPrW60u5ouWybWMYBu2nt+fXfb9mW27DhoH541cvtB5j25hpf9zKcSSlJfFovUfpUrULyenJ+Hv6U9KvJMnpyQyaN4glB5bwSadPaF2udf680RxwOODgQfMWEbt3m0NY5cqZE4/37YNly+CHH3I2hydLiRJw223mlZd37zbP/OrdGxo2NIfO4uPNCxJWr25uIyKS15bsX8Ltn98OmGfB7hu0L1+OqzBzAYWZgmHv6b20/aItDsNBhaIVuL3c7fS7pR9zds1h2MJhxKfGX/H1Nmy0r9ieY4nH2BS7CQAvNy9m3jeTzlU6Z9vWkelgY+xGapWshZe7F9tPbOeNVW/QtHRT+tTtg6ebJwAnk0/Sb24/mpdpzpCmQwDzFhF+Hn5UC66W998EzG7OnDnmdXL8/c3ws3OnOZE5ONjs/iQnw6ZN5mTmlJSc7zs83Bwe8/Ex912rltnZyTqFvU0bM1yJiFyLyWsnM3DeQMD8XZz4f4n5Mv/xhgozR44cYfjw4cybN4/k5GQqVqzI1KlTadCgQY5erzBT8J1IOsHYFWN5f937ADzV8CnKBJRh8rrJ7DuzD18PX+fkY4Bg32DqhNZh0d+LcLO5MaHtBAY3HozNZiM1I5Ue3/Xgx10/EhEYQbdq3ZiyfgopGWYqiAiM4NXWr3JfjfuI+jyKlYdX4mZzY/uA7SSmJdLw44b4efix++ndhPqHWvL9yJKWZt7pfPlyM5BUqmR2Zz77zJzAXLMmFCv2zxWZc6JBAwgIMANTSooZcurVg06dzMnLYA59RUTo2jwiYnrq56eYsn6K8/n6fuupH17/uh/3hgkzZ86coV69erRu3Zonn3yS4OBg9uzZQ4UKFahQocLVd4DCTGFyMvkkNmzOWykYhoHDcOBud2fv6b189OdHxCTEMC5qHOFFwnlszmPOu4Z3rtKZuyrdxXc7vrtoOAugWZlm7Duzj9jEWABC/UOdXwPcX/N+DiccZsWhFQA8Vu8xPu788SXrNAyDL7d8yZbjW3il1Sv4e+b/RWoyM7PPpYmPN+fxHDpkhqBTp8zuzt69ZpcmORlWrMj5NXq8vMyLDZYoAcWLm/9mPUqXNoe1SpY0A5GPjxmEdFVmkbwxf+98FuxdwPg7xjs7yVZqFd2K3w/+7nw+rcs0Hqrz0HU/7g0TZl544QVWrlzJ8uXLc70PhZkbl2EYTFo7iSG/DiE985+JKH4efsy8byY7T+7kyy1f8mDtB3nm1mdIzUjlnTXvMOb3MaRkpOBud2dcm3EMXTjU+VovNy9SHanYsPFl1y/5+q+vSXOk8eFdHxIZFMnZ82fpP7c/327/FoBu1bsxs9vMy153B8xhr2uZ3Lzz5E6CvIPyvDN07Jh5w1C73QwgPj5mKPrtN/PWE0lJ5vOYmJxNZL6Qv785SbpYMXNej91uTmSOjDSHtrIeERHgaf3vZpECyzAMIidGcjjhMNO7TueBWg9YXRLBbwRzMvkkTUo3YXXMap5v+jzj7xh/3Y97w4SZ6tWr065dO2JiYvj9998pVaoUTz31FP369bvsa1JTU0lNTXU+T0hIoEyZMgozN7A/j/7JR39+xLHEYwD8323/x62lb73s9vvP7OfN1W/StkJbOlfpTLeZ3fh+x/cAjG41mm0ntjFz28xsrynqXZSu1bry3fbviE+Nx91u3nA+IzODcW3GMbz5cABS0lPYfWo3VUpUIc2RxvMLn2fa5mk83/R5RrUaxcnkk3z050c0j2hOy7ItL6ptU+wmGn7ckDD/MLYP2G5J18fhMDs8sbHmGVYXPk6cMK+5s22b2Q3y8TG7Pjmd1Gy3mx2fcuXMoOPjY96Hy939n3lD4eHm6fIxMVC7NnTrZg6zzZtnBqWoKPN1Wb+5LpcjU1LMiyaWLJk33xeR/LDz5E6qTTbn7A1sOJD37nzP0npOJJ2g5ISS2LDxxh1vMHThUDpW6shPD/x03Y99w4QZb29vAJ577jnuu+8+1q1bx+DBg/nggw/o06fPJV8zatQoRo8efdFyhRm5nG1x26j/UX1KBZRi65NbiUuKo8b7NUhOT6Z7je4cOHuAtUfWOrevUrwKn9/zORuObeDJn5/Eho2WZVtSrUQ1vtn2DadTTuPl5oW/pz+nUv65Il+vWr34bf9vztDVqmwrRrUclS3UtP+yPQv2LQDglZavMKrVqPz5JrggPd0czjpwwLz/1rlzZtBISjKX7d//z+NaJjRnCQzMHpj8/Mybl8bEmB2hZs3MU9kTEsywVL68OYfoyy/NZbfdZp4BFhxs7qtmTfNrwzBDkpeX9ae/Hz13lI/+/IiBjQZSwreEtcXIdZGSnkLraa0p4lWEeb3mOf+H6N/eW/Meg+YPAqB+WH3W97/Gi11dxomkExTxKoK3u/c1vW7pgaW0ntaackHliO4STcvolpQNKsv+wfvzpK4ruWHCjKenJw0aNGDVqlXOZYMGDWLdunWsXr36kq9RZ0Zy48DZAxTxLOKcr7P71G4yMjOoHlydNEcao5eOZt+ZfTxS9xHuqHAHdpsdwzB4bsFzTFwzMdu+vN29OZ9xHoAKRStwT9V7mLB6gnN9RGAEsYmxpDnMsZysUJNpZDpPfwTwcfdhz9N7KBVQKtv+UzNSOXv+LCX9SrLh2AaGLxrO1ritPF7/cQY1HlQg/xgeSTjCzG3fcneZfsTF+LF/Pxw+bA5nZWSYj9RU82yvo0fNG4eWLAk//wwHjeUQH0HNMpEkJJhdI1cVLWre9iIrIGXdlNTf37yoYcuWZsA5dcqcM5QesoY29SpQu2KJ6zI3qOs3XZm1cxb317yfr+79Ku8PIJb76M+PePynxwF4t/27PN346Utu13lGZ+bunguAm82N+Bfi8fP0y9UxDcMgelM0H2/4mNUxq2kR2YKlfZZis9n4effP+Hr4XvXyFu+ve58Bvwzgrsp3EX13NCXeMH+/nBtx7rp3jm+YMBMZGckdd9zBJ5984lw2ZcoUXn31VY7k8PQNzZmR6+3A2QN8t/07dp/azd1V7qZ9xfbsOb2H/Wf207JsS3w9fPl0w6c8v+h57qt+H2+1e4tTyacYt2Icn2z8xBlq/Dz8SEpPYkDDAWyK3cTKwytpWqYpHSp2oFSRUpQKKMXyg8t5f/37nE45fdFZXmD+8itftDxlg8riMBx42D24r/p9PFDrAXw8fACYunEqA+cNJMw/jPrh9RnWdBgNwnN2dmBuODId3Prpraw/up6+9frySedPrv6i//l172LaTY+iuFdJtg7YRKh/GJs3m92f0qUhLs482+vkSbPrkpYGv5yczEnvPxjX+k2a1C7Jp5+a1/hJTjaHyfZd6yUyqn0PPbrBqYoEz/qTcuEBFPnfDeVTUsyzwypXNidHG4Y5ZBYQYA6nNWtmdoFOnDCH5SIizE5QFsOArYcPUi+6PJlGJnabnV0Dd1GxWMVrLLJgc2Q6sNls2G0F9wqQaY40Tqecds5VMwyDo+eOAhDgFUARryK53rdhGNR4vwY7Tu4AIMg7iN0Dd7Pz5E5sNhvNI5oDkO5Ip/jrxTmXdg4Puwfpmeks7bP0oiHpjMwMVh1eRaNSja7YaZmybgpP/fJUtmXLHl6Gr4cvDT5ugLvdnU2Pb6JGyRoX1Zs1D3DAzwN4f/37DG82nHFR4wiZEEJcUhxrH1tLw1INc/09yYkbJsw88MADHD58ONsE4GeffZY1a9Zk69ZcicKMFBQX/oLIcjj+cLZQ4+fhx75B+zgYf5DGnzTO0X4frP0gbcu3ZeKaiWw4tuGS2xTzKcZj9R6jhG8Jnl/0fLZ1fh5+/PzAzxgYvLHqDfw9/WlfoT0JqQmsObKGSsUq8VyT54hJiGHw/MHYbXYm3zkZTzdP+s7py99n/ubhug/T75Z+l7w1xYX/RwrwR98/aFz60u9t2cFlPPLjI/Ss0ZNXb3+VJp82Yc2RNQC0Ltuahb0XXnEy9a/7fqXdl+0AqFqiKot6L7qos3XunDn8FRRkBqDUVDPoJCWZoWjFCli5JgVfTx+KFE9kRvGqnPf83/88be0J338F5Lw94+OfTkrjV6DKHEjzx8cRRpnUtkSc78Tm5aU5UXsE3DbOuX19W18eDPgELy+yPTw9zX+9vc3rBxX0uUDJ6cn0ndOXhfsWcjrlNOWKlmPFIyuuePuSTCOTw/GHiQyKvGhduiOdZQeXserwKh6q85Bzm0v9d3WtUjNSuf3z21l7ZC2LH1pMi8gWPP3L00xaNwkwu60fd/qYB2s/CJg36g3wyv73JDYxlnf+eIc25dsQVT6KPaf28NDsh6hcvDJ3VryTnt/3pIhnESKDIvkr7i+KehflzPkzAMy9fy53Vb6LFYdWcNvU2yjhW4LbIm5j1s5ZjG0zlheav5DtWH1/7Mtnmz6jcvHKfNzpY1pEtrjoPcUkxFB9cnXOpZ3jmcbPcDzpODP+msG91e4lzZHm7P5c2K1JSkui04xOrDmyhqZlmhLgFcD8vfNJTk92nsF0+7TbWXJgSbbbGiSnJ+Pj7uPy5/BvN0yYWbduHU2bNmX06NF0796dtWvX0q9fPz766CN69eqVo30ozEhhcDj+MJ9u/JSmZZrStkJbwPzDvPLQSmISYjhy7ggxCTEE+wUzsOFAOlbuSExCDJ5unkQERgDmL/Uj546w6+Qujpw7gofdg0Pxh/jgzw84cPZAtuM93ehpOlfpzPiV41n09yLn/wVeTnGf4iSkJji38fXwxcPuke1ih55unjzT+Bl61OzBzG0z2XVqFy0iWvDq8lc5nXKaiMAIDsUf4pawW+hcuTNrjqzhjvJ30K9+P/w9/dkcu5kW0S1ISE0A4KE6D/H55s/xcffBbrOTlJ5E+4rtKR9UnurB1elRswclfEuQmJbovCFqrSm1OHruKO52dzIyMygdUJru1bvTqmwr7qx0J252NwzDYN3RdXyy4RNWHFrBqFaj6F6jOwDnUs/x0m8vMWndJJqUbkJkUCRfbf2KMP8w4pLicBgObivaE6/MYlTwbkib4Ac5e9qd3bvh7FmI815BknGKoON3sXuXG1v/Pg739YCyv1/0PSXTDn88A3Wnge8pWDkMmr0BDg94Zx8klAH3FKj9JXgmQWII/B0FyeZt3LMuiugedAzPwHiK+nuRlpHJybMpJHru43zRDYQHFefh6gPx8bZz5Ig5ubtaNXNekZsbuLkZJDrOsPbIWmb8NYO/4v6iS5UuDGw0kKI+RXPzowyYXY7OMzo7539laVamGT/2/JGRS0ay/+x+Pr/nc+ewaJojjTun38ni/YuZ1GESAxoNAMyrjL/9x9tM/GOicw5a0zJNWfHICjbFbqLTjE7cUeEOPrrro6vezfnC4PPB+g/YFreNZ5s8y9jlY/lko9kxrFWyFu93fJ/bpt4G4PxZ8nb3Zvkjy/ls42dMWT+FB2s/yCedPsHTzZMfd/1Iv7n9nJeXGNJkCF9u/TLb5R8Anmn8DF2rdaVFtBk+sq6CHuQdxJ/9/2TapmmMWTaGHjV60DC8IUMXDqVzlc782PNH5z4uvBpvlheavcBrbV5zdr4Mw6Dz1535afdPNCndhOWPLGfHyR3UmlILu83u7AJ6unlyPuM8n3f5nJ41e3LPN/fw856fL/q+lQsqx8pHVxJWJIyvtn5Frx/Mv79f3vMlx5OOM37leKZ1mUb7iu2v+P2/VjdMmAH46aefGDFiBHv27KFcuXI899xzVzyb6d8UZuRm58h08NPun3hv7Xv8tv83nm/2PGPbjMVms3E+4zz3zryXX/b8gg0bj9d/nGC/YBbvX0ygVyANwxsyc7t5mjvAXZXvIjEtkaUHlgLQuFRjHrvlMT7b+BmrYy49jw3MPxDzes2jxvs1Lrrac1HvolQuXpk9p/dwOuU0IX4hHE867lw/tMlQ6obW5cFZD2Z7nYfdgxD/EGISYgBzjlFKRgqVi1dmVo9ZdJrRib/P/O3cvkrxKnSv0Z1ZO2fxV9xfzuU2bIyLGkemkcmktZM4cu7iIeyf7v+JbSe2MXzR8GzLKxWrxIjmI+harSvvrnmXkUtHAlAjuAb1wurx3bbvOO84TxHPIrzV7m080kvwx94dLDo8h72p/3y/QrwieMF3H2+fvINDbksJSYqi4d8/sKZMT04E/eLczp4WSLFN/+Hk/lJQbjGUXwwldl32+w7Apj4wfyLUnWpuG3MrpPlB7elQ7jfwOnfRS+yZXvi5FcXTw/y/9fTMdGrbH2DkrW/gWWYTH215hxPJJ8g0MqkTUof7qt9HvbB6eLt7s+rwKt5c/Sbz987H18OXb+/7lmDfYKK+iCIhNcH5OQHcW+1evr3PvMzBo3MeJXpTNGBeImFdv3VsP7GdZxY84wwFJXxLkJCaQJojjV8f/JVXlr7i/Lm7p+o9fN3ta9xsbiz8eyHfb/+eEP8QBjUexI4TOxg4byDudne+7/49Kw+t5KHZ5nVS3GxuOAwHNmz4e/pzLs2cC5KYlsjDdR/m086f0nlGZ37e87Nz2yyNSjUiNSOVzcc3AxDmH+ac4A9Qs2RNzqWe42D8Qew2O3uf3ku5ouX4YvMXxCXF0at2L7p+05XVMasJ8AogKS0Jh+Hgk06fUC24Gs0+a0awbzDfdf+O3w/8Tq2QWgxfNJzdp3bzcN2H8bR78tGGjwDzWlsjmo8gIzODUUtHsXj/YjzdPNn4+EaqB1cHoM3nbfht/28A9K7dm2olqvF/v/2f83t7MvkkPu4+TOsyjbikOM6eP0vbCm2pH14/2xDhM/Of4Z0172T7melWvZvzs8wrN1SYcZXCjMg/0hxpF12EKzUjlS+3fEn98PrUDa170WvSHel8tfUrivoUpVPlThgYTN04lcS0RJ5q+BQebh4YhsHPe35m6K9D2XN6Dx0qdqBJ6SbM2zuP/Wf3M6vHLBqVasTnmz/n6XlP06xMM5qVaUb05mj2nt7rPFbtkNos7bOUB2c9yC97fsHPw4/9g/cT7BfMor8Xse7IOhLTEpm/b/4lh9Q87B6seHQFjUo1Iv58PHN3z2XFoRV8u/1bTqecdm7n7e5Nt+rd8LB7MHXT1Gz7KF+0POPajOPnPT8zbfM0Hqj1ANO7TifTyOSTDZ9wOP4w5zPOE705mpPJJwGy/ZH791ymW8Ju4ct7vrzoFhk/7f6J/nP7cyzxGG+2fZPnmjzHn0f/pGV0S5LSkwj2DeZE8gl83H3oXKUzW45vcc65uJANO15GIBlGKjbseNh88DNC8U2qxiH/7zFsDrPb43aF8+cTSsHOLnC8FjR8H0K3XHq7NF/wTL70un9xt3kyvPRP1ClyBxkZsC5hDm/H3g2Y4e1U2lEyjAxej3qd7Se3E70pGrvNTu2Q2myK3USAV4CzS1e+aHlebf0q3Wt0Z8ivQ3hnzTvZ/vhmGpmkOswTP7I6KVkunJAP5hXEE1ITSHWkUrl4ZXaf2g3Af2//L8V8ivHEz08A5ryWXQN3UdKvJKdTTnPLh7dwMP4gvh6+jGg+ggmrJjiDuZebF4MbD2ZM6zFEb4pm8PzB3BJ2i/P05deWvUa14Go8dstjF32fYhJiqP9RfeKS4gDzBIH1/dZTxKsIAWMDLtkxDfUPZeeAnQR6BzJ9y3T6zunrfP9ZPN08ea/De/Sv39+57MedP9Llmy7YbXZ2DNhB2aCy2TpobjY3838EqnS64mebkZnBXV/dxYJ9CygbVJaXW7xM79q9r9oZu1YKMxdQmBHJP4ZhkJGZkeNfao5MB6tjVnMm5QyZRiZ3VLgDXw9fzqScYdjCYbSt0NY5BPRvO07s4Oz5s1QpUQUPuwd7Tu8hwCvgkpNnE1ITeG/Ne6w9upZ2FdrxQK0HCPIOwjAM/rv8v4z6fRRNSjehT50+2SZLx5+Pp4hXkUtOXD2Xeo7J6yYTvSmaXad24WH34P2O79Otejcmr53M8aTj3F/zfm4tfetl5xKcPX+WTbGbaBnZ0rnNsoPL6DC9A8npybjZ3Pix5490rNwRR6aDjzd8zLgV4/Dx8CGqXBRR5aNoWbYlQd5Bl9z/jzt/pPt33UlzpFGxWEXuqnQXa46s4WTSae6q2IW2pbqTeqQqcUd8CQgwz+hKSDDYeGgPf6xPYecugyrl/ahQ7zCz0weQ4LnTDEbrH4cDrcGeAeUXQdVZ4GcGO5JKmMHoz/5w9F8TRGvOgBI7YfUQaPQetHkp2+pbjk2mnlc3vi5amyTbcey48VStF+lV5kUS4z0pXx68ih+j4qTyzoDyautXaRDegJ7f9eRs6lnAnCPWqVx3tpxaz8bj5qnNj9V7jHVH1zm7KJ2rdGZWj1ksP7ico+eO0rNmTzKNTOdk9ffvfJ8nGz6Z7edt8rrJ9LulH3VC67D9xHbGrRhHg/AGPFj7QYr5FHNum5iWiJ+HX47nkMQkxLDr5C4qF69M6YDSztc1/6w5Kw+vxMPuQcfKHdl5cicHzh5gZreZ2QLHHzF/8H+L/4+/z/zNmfNn6FCxA2PbjL3opr+ZRiZjfh9DZGAkj9R7xLn8VPIptsZtpZhPMWqH1M5RzWmONNYeWUujUo2u21WKFWYuoDAjIldzrVdpvpBhGGyN24qPuw+VilfKk3qWHVzGyCUjebLBk/So2cOlfW2O3cyh+EN0qNThstc2yYnzGeeZs2sOZeyNObo9ksxM8yKG/v7mpOSNW9JZvCyZs8f9yXS44XCYc3QMI2t+jvlISTGvRn00NoOke9tA2WWwpz2seAEO/u+snVJrocEUWP8EHMk+WdzXF9LbPEN6/XdwOxdJneU7OHHMh8NHUwkKO0Pd+mnE/R3K9q2euHsY1LtnCdXKBxCc3gC7TwJL/QaQbkugu8cXeNsCKFHCPOOsZElzgvWuQ6fYFb+Jp++6HX9/a+/RsS1uG3N3z6VnzZ6UDSoL5M2E58JCYeYCCjMiIgXT6fg0dhw8heNsGMeOmSEnLs48jT0uzrzf2N9/m7fJCAgwv05LA7wSoMWr8FdPOHbLdanNx8e803xkpBl2goPNZdu2mXXUrQtt25rh6tw587pFSUlmKKpY0byw44WZwzDM6xq5u1t/kcbCQmHmAgozIiI3hvR080rSdrt5+4u4OPNqz8HBZoA4eBDWrTOv+RMVZa6fM8e8GKO7uxk2jh0zA1FAgBkwTp40tztxwrwidHj4P1evdkWRIlChgnmsmBjzatRg1l26NFSpAo0amRdw3LHDfE+dO5vXJkpIMN/L1q3mbUVCQ833mJZmXmV7+3bzfbRrB/ffj/O6R2AGK1/fG+Ou9wozF1CYERGRa2EY5l3nly//J+icPGmGjCpVoGxZWLXKvCaR3W4OtRUpYnZujh0zg0h+/WX194eOHc3bdsyZA7/+ai6rX98MbGlpZqhq0cK8kGNmpjn8l5n5z8PHxwxMoaHm+7iWUSyHA775xgxi/nl8QWCFmQsozIiISH5KTTWHovbtM+fhlCljDpV5embvuvzxh3nBxqpVzY7LDz+YnRh3dzNY1Kxpvvb4cTNMeXubYaNyZfPfL7+E3bvztnYfH3MieNZ91IoVM0NKWto/D09P6NoVGjSA8ePhr7/gP/+Bl1668r6vlcLMBRRmRESkMMjMNIe4/P1z1h0xDFizBn78EVavhltvhcceM4fL/vzTHJZzc4PNm80uUtbNWN3csv+blGSGqKyhsGsVFARjxsDTl77dVK5dy9/v3E9tFxERkTxjt2ef/3I1NpsZYG699eJ1NWte+/GTk80uUFKS2aExDLNjlJj4z+00vLzMm71+9hls3Ag9esDzz5tzf6ykMCMiIiL4+kK5clffrlYtc55OQaITxERERKRQU5gRERGRQk1hRkRERAo1hRkREREp1BRmREREpFBTmBEREZFCTWFGRERECjWFGRERESnUFGZERESkUFOYERERkUJNYUZEREQKNYUZERERKdQUZkRERKRQU5gRERGRQs3d6gKuN8MwAEhISLC4EhEREcmprL/bWX/Hr+SGDzPnzp0DoEyZMhZXIiIiItfq3LlzBAYGXnEbm5GTyFOIZWZmcvToUYoUKYLNZsvTfSckJFCmTBkOHz5MQEBAnu5bXKPPpmDS51Jw6bMpuG7Wz8YwDM6dO0d4eDh2+5VnxdzwnRm73U7p0qWv6zECAgJuqh+wwkSfTcGkz6Xg0mdTcN2Mn83VOjJZNAFYRERECjWFGRERESnUFGZc4OXlxSuvvIKXl5fVpci/6LMpmPS5FFz6bAoufTZXd8NPABYREZEbmzozIiIiUqgpzIiIiEihpjAjIiIihZrCjIiIiBRqCjO5NHnyZMqWLYu3tzeNGzdm7dq1Vpd00xk1ahQ2my3bo2rVqs7158+fZ8CAARQvXhx/f3/uvfdejh8/bmHFN65ly5bRqVMnwsPDsdlszJ49O9t6wzAYOXIkYWFh+Pj4EBUVxZ49e7Jtc/r0aXr16kVAQABBQUH07duXxMTEfHwXN6arfTYPP/zwRf8dtW/fPts2+mzy3tixY2nYsCFFihShZMmSdOnShV27dmXbJie/ww4dOkTHjh3x9fWlZMmSDBs2jIyMjPx8KwWCwkwufPPNNzz33HO88sorbNiwgTp16tCuXTvi4uKsLu2mU6NGDY4dO+Z8rFixwrnu2WefZe7cuXz77bf8/vvvHD16lK5du1pY7Y0rKSmJOnXqMHny5Euuf/3113n33Xf54IMPWLNmDX5+frRr147z5887t+nVqxfbtm1j4cKF/PTTTyxbtoz+/fvn11u4YV3tswFo3759tv+OZsyYkW29Ppu89/vvvzNgwAD++OMPFi5cSHp6Om3btiUpKcm5zdV+hzkcDjp27EhaWhqrVq1i2rRpREdHM3LkSCvekrUMuWaNGjUyBgwY4HzucDiM8PBwY+zYsRZWdfN55ZVXjDp16lxy3dmzZw0PDw/j22+/dS7bsWOHARirV6/OpwpvToAxa9Ys5/PMzEwjNDTUeOONN5zLzp49a3h5eRkzZswwDMMwtm/fbgDGunXrnNvMmzfPsNlsxpEjR/Kt9hvdvz8bwzCMPn36GHffffdlX6PPJn/ExcUZgPH7778bhpGz32G//PKLYbfbjdjYWOc2U6ZMMQICAozU1NT8fQMWU2fmGqWlpfHnn38SFRXlXGa324mKimL16tUWVnZz2rNnD+Hh4ZQvX55evXpx6NAhAP7880/S09OzfU5Vq1YlIiJCn1M+279/P7Gxsdk+i8DAQBo3buz8LFavXk1QUBANGjRwbhMVFYXdbmfNmjX5XvPNZunSpZQsWZIqVarw5JNPcurUKec6fTb5Iz4+HoBixYoBOfsdtnr1amrVqkVISIhzm3bt2pGQkMC2bdvysXrrKcxco5MnT+JwOLL98ACEhIQQGxtrUVU3p8aNGxMdHc38+fOZMmUK+/fv57bbbuPcuXPExsbi6elJUFBQttfoc8p/Wd/vK/03ExsbS8mSJbOtd3d3p1ixYvq8rrP27dvz+eefs3jxYsaPH8/vv/9Ohw4dcDgcgD6b/JCZmckzzzxDs2bNqFmzJkCOfofFxsZe8r+rrHU3kxv+rtly4+rQoYPz69q1a9O4cWMiIyOZOXMmPj4+FlYmUnj07NnT+XWtWrWoXbs2FSpUYOnSpbRp08bCym4eAwYM4K+//so250+ujToz16hEiRK4ubldNKP8+PHjhIaGWlSVAAQFBVG5cmX27t1LaGgoaWlpnD17Nts2+pzyX9b3+0r/zYSGhl40gT4jI4PTp0/r88pn5cuXp0SJEuzduxfQZ3O9DRw4kJ9++oklS5ZQunRp5/Kc/A4LDQ295H9XWetuJgoz18jT05P69euzePFi57LMzEwWL15MkyZNLKxMEhMT2bdvH2FhYdSvXx8PD49sn9OuXbs4dOiQPqd8Vq5cOUJDQ7N9FgkJCaxZs8b5WTRp0oSzZ8/y559/Orf57bffyMzMpHHjxvle880sJiaGU6dOERYWBuizuV4Mw2DgwIHMmjWL3377jXLlymVbn5PfYU2aNGHr1q3ZwubChQsJCAigevXq+fNGCgqrZyAXRl9//bXh5eVlREdHG9u3bzf69+9vBAUFZZtRLtffkCFDjKVLlxr79+83Vq5caURFRRklSpQw4uLiDMMwjCeeeMKIiIgwfvvtN2P9+vVGkyZNjCZNmlhc9Y3p3LlzxsaNG42NGzcagPHWW28ZGzduNA4ePGgYhmGMGzfOCAoKMn788Udjy5Ytxt13322UK1fOSElJce6jffv2Rr169Yw1a9YYK1asMCpVqmTcf//9Vr2lG8aVPptz584ZQ4cONVavXm3s37/fWLRokXHLLbcYlSpVMs6fP+/chz6bvPfkk08agYGBxtKlS41jx445H8nJyc5trvY7LCMjw6hZs6bRtm1bY9OmTcb8+fON4OBgY8SIEVa8JUspzOTSe++9Z0RERBienp5Go0aNjD/++MPqkm46PXr0MMLCwgxPT0+jVKlSRo8ePYy9e/c616ekpBhPPfWUUbRoUcPX19e45557jGPHjllY8Y1ryZIlBnDRo0+fPoZhmKdnv/zyy0ZISIjh5eVltGnTxti1a1e2fZw6dcq4//77DX9/fyMgIMB45JFHjHPnzlnwbm4sV/pskpOTjbZt2xrBwcGGh4eHERkZafTr1++i/zHTZ5P3LvWZAMbUqVOd2+Tkd9iBAweMDh06GD4+PkaJEiWMIUOGGOnp6fn8bqxnMwzDyO9ukIiIiEhe0ZwZERERKdQUZkRERKRQU5gRERGRQk1hRkRERAo1hRkREREp1BRmREREpFBTmBEREZFCTWFGRG4KNpuN2bNnW12GiFwHCjMict09/PDD2Gy2ix7t27e3ujQRuQG4W12AiNwc2rdvz9SpU7Mt8/LysqgaEbmRqDMjIvnCy8uL0NDQbI+iRYsC5hDQlClT6NChAz4+PpQvX57vvvsu2+u3bt3K7bffjo+PD8WLF6d///4kJiZm2+azzz6jRo0aeHl5ERYWxsCBA7OtP3nyJPfccw++vr5UqlSJOXPmONedOXOGXr16ERwcjI+PD5UqVboofIlIwaQwIyIFwssvv8y9997L5s2b6dWrFz179mTHjh0AJCUl0a5dO4oWLcq6dev49ttvWbRoUbawMmXKFAYMGED//v3ZunUrc+bMoWLFitmOMXr0aLp3786WLVu488476dWrF6dPn3Yef/v27cybN48dO3YwZcoUSpQokX/fABHJPavvdCkiN74+ffoYbm5uhp+fX7bHa6+9ZhiGeQfhJ554IttrGjdubDz55JOGYRjGRx99ZBQtWtRITEx0rv/5558Nu93uvMNzeHi48eKLL162BsB46aWXnM8TExMNwJg3b55hGIbRqVMn45FHHsmbNywi+UpzZkQkX7Ru3ZopU6ZkW1asWDHn102aNMm2rkmTJmzatAmAHTt2UKdOHfz8/JzrmzVrRmZmJrt27cJms3H06FHatGlzxRpq167t/NrPz4+AgADi4uIAePLJJ7n33nvZsGEDbdu2pUuXLjRt2jRX71VE8pfCjIjkCz8/v4uGffKKj49Pjrbz8PDI9txms5GZmQlAhw4dOHjwIL/88gsLFy6kTZs2DBgwgAkTJuR5vSKStzRnRkQKhD/++OOi59WqVQOgWrVqbN68maSkJOf6lStXYrfbqVKlCkWKFKFs2bIsXrzYpRqCg4Pp06cPX375JRMnTuSjjz5yaX8ikj/UmRGRfJGamkpsbGy2Ze7u7s5Jtt9++y0NGjSgefPmTJ8+nbVr1/Lpp58C0KtXL1555RX69OnDqFGjOHHiBE8//TS9e/cmJCQEgFGjRvHEE09QsmRJOnTowLlz51i5ciVPP/10juobOXIk9evXp0aNGqSmpvLTTz85w5SIFGwKMyKSL+bPn09YWFi2ZVWqVGHnzp2AeabR119/zVNPPUVYWBgzZsygevXqAPj6+rJgwQIGDx5Mw4YN8fX15d577+Wtt95y7qtPnz6cP3+et99+m6FDh1KiRAm6deuW4/o8PT0ZMWIEBw4cwMfHh9tuu42vv/46D965iFxvNsMwDKuLEJGbm81mY9asWXTp0sXqUkSkENKcGRERESnUFGZERESkUNOcGRGxnEa7RcQV6syIiIhIoaYwIyIiIoWawoyIiIgUagozIiIiUqgpzIiIiEihpjAjIiIihZrCjIiIiBRqCjMiIiJSqCnMiIiISKH2/1vrWstAba0NAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"loss\"], 'b', label='Training loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], 'g', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107/1107 - 1s - loss: 5.8596 - 718ms/epoch - 649us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.85959529876709"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_eval.values.astype(np.float32),  y_eval.values.astype(np.float32), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9956/9956 [==============================] - 5s 484us/step\n",
      "[[-0.00161982]\n",
      " [ 1.0689433 ]\n",
      " [-0.00469404]\n",
      " ...\n",
      " [ 1.1079342 ]\n",
      " [ 0.38836724]\n",
      " [ 1.0198526 ]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_train.values.astype(np.float32))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[\"favorites_count\"], model.predict(X_train))\n",
    "# plt.scatter(X_train[\"favorites_count\"], y_train.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "eval_data = pd.read_csv(\"data/evaluation_with_embeddings.csv\")\n",
    "tweets = eval_data[\"TweetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['avg_word_count', 'compound'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m eval_data \u001b[39m=\u001b[39m eval_data\u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39murls\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmentions\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhashtags\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTweetID\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39m# normalize\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m eval_data\u001b[39m.\u001b[39mloc[:, normal_columns] \u001b[39m=\u001b[39m (eval_data\u001b[39m.\u001b[39;49mloc[:, normal_columns] \u001b[39m-\u001b[39m mu) \u001b[39m/\u001b[39m sigma\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(eval_data)\n\u001b[1;32m     25\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(eval_data\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/hexa/hexa/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['avg_word_count', 'compound'] not in index\""
     ]
    }
   ],
   "source": [
    "eval_data[\"url_count\"] = eval_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"text_len\"] = eval_data[\"text\"].apply(lambda s: len(s))\n",
    "eval_data[\"hashtags_count\"] = eval_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"day\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "eval_data[\"hour\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "eval_data[\"Macron\"] =  eval_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "eval_data[\"Zemmour\"] =  eval_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "eval_data[\"Melenchon\"] =  eval_data[\"text\"].apply(lambda s: (\"melenchon\" in s.lower().split()))\n",
    "eval_data[\"rt\"] =  eval_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))\n",
    "eval_data[\"avg_word_len\"] = eval_data[\"text\"].apply(lambda s: np.mean([len(w) for w in s.split()]))\n",
    "eval_data[\"rep_words_freq\"] = eval_data[\"text\"].apply(lambda s: np.mean(len(list(set(s.split())))/len(s.split())))\n",
    "eval_data[\"rep_chars_freq\"] = eval_data[\"text\"].apply(lambda s: np.mean(len(list(set(s)))/len(list(s))))\n",
    "eval_data[\"max_char_freq\"] = eval_data[\"text\"].apply(lambda s: max( [s.count(c) for c in list(set(s))] )/len(list(s)))\n",
    "\n",
    "# print(\"sentiment analysis...\")\n",
    "# eval_data[\"compound\"] =  eval_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])\n",
    "\n",
    "eval_data = eval_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "\n",
    "# normalize\n",
    "eval_data.loc[:, normal_columns] = (eval_data.loc[:, normal_columns] - mu) / sigma\n",
    "\n",
    "print(eval_data)\n",
    "\n",
    "pred = model.predict(eval_data.values.astype(np.float32))\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# output normalization\n",
    "for i,p in enumerate(pred):\n",
    "    if p<0: pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9171066e-02]\n",
      " [1.4402901e-01]\n",
      " [3.0538517e-01]\n",
      " ...\n",
      " [2.8213394e+00]\n",
      " [2.3125261e-03]\n",
      " [1.4682983e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/predictions.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"retweets_count\"])\n",
    "    for index, prediction in enumerate(pred):\n",
    "        writer.writerow([str(tweets[index]) , str(int(prediction))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b76f9357de510751682414c7cddbaacea429d985ca72e90da955bd41bf6fe1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

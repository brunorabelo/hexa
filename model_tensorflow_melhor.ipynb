{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'retweets_count', 'favorites_count',\n",
       "       'followers_count', 'statuses_count', 'friends_count', 'mentions',\n",
       "       'urls', 'verified', 'hashtags', 'timestamp', 'TweetID', '0', '1', '2',\n",
       "       '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
       "       '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27',\n",
       "       '28', '29', '30', '31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features\n",
    "train_data[\"url_count\"] = train_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"text_len\"] = train_data[\"text\"].apply(lambda s: len(s))\n",
    "train_data[\"hashtags_count\"] = train_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"day\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "train_data[\"hour\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "\n",
    "# text features\n",
    "train_data[\"avg_word_len\"] = train_data[\"text\"].apply(lambda s: np.mean([len(w) for w in s.split()]))\n",
    "train_data[\"rep_words_freq\"] = train_data[\"text\"].apply(lambda s: np.mean(len(list(set(s.split())))/len(s.split())))\n",
    "train_data[\"rep_chars_freq\"] = train_data[\"text\"].apply(lambda s: np.mean(len(list(set(s)))/len(list(s))))\n",
    "train_data[\"max_char_freq\"] = train_data[\"text\"].apply(lambda s: max( [s.count(c) for c in list(set(s))] )   /len(list(s)))\n",
    "train_data[\"avg_word_count\"] = train_data[\"text\"].apply(lambda s: len(s.split()))\n",
    "\n",
    "train_data[\"log\"] = np.log(0.1 + train_data[\"favorites_count\"])\n",
    "\n",
    "# indicators of keywords\n",
    "# train_data[\"Macron\"] =  train_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "# train_data[\"Zemmour\"] =  train_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "# train_data[\"Melenchon\"] =  train_data[\"text\"].apply(lambda s: (\"melenchon\" in s.replace(\"é\",\"e\").lower().split()))\n",
    "train_data[\"rt\"] =  train_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>verified</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>rep_chars_freq</th>\n",
       "      <th>max_char_freq</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>log</th>\n",
       "      <th>rt</th>\n",
       "      <th>text_arr</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt refarcir macron ans nom prépare</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3682</td>\n",
       "      <td>453535</td>\n",
       "      <td>3628</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, refarcir, macron, ans, nom, prépare]</td>\n",
       "      <td>rt refarcir macron ans nom prépare</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>populaire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1016</td>\n",
       "      <td>284</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[populaire]</td>\n",
       "      <td>populaire</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faut dégager cinglé</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>28234</td>\n",
       "      <td>1995</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>3</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>False</td>\n",
       "      <td>[faut, dégager, cinglé]</td>\n",
       "      <td>faut dégager cinglé</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enseignants mettre prescriptions président rép...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/rytlted08g']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>14</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[enseignants, mettre, prescriptions, président...</td>\n",
       "      <td>enseignants mettre prescriptions président rép...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mafieuse oppressive macron</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13957</td>\n",
       "      <td>25311</td>\n",
       "      <td>10841</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[mafieuse, oppressive, macron]</td>\n",
       "      <td>mafieuse oppressive macron</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353964</th>\n",
       "      <td>gonflette tour raciste frustré</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1509</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/pma33zhslx']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[gonflette, tour, raciste, frustré]</td>\n",
       "      <td>gonflette tour raciste frustré</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353965</th>\n",
       "      <td>france caste crapuleuse encadrée gangsters irr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>11166</td>\n",
       "      <td>127</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[france, caste, crapuleuse, encadrée, gangster...</td>\n",
       "      <td>france caste crapuleuse encadrée gangsters irr...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353966</th>\n",
       "      <td>eric zemmour français berbère</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1888</td>\n",
       "      <td>712</td>\n",
       "      <td>3086</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[eric, zemmour, français, berbère]</td>\n",
       "      <td>eric zemmour français berbère</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353967</th>\n",
       "      <td>gauchistes dépression pq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>486</td>\n",
       "      <td>320</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[gauchistes, dépression, pq]</td>\n",
       "      <td>gauchistes dépression pq</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353968</th>\n",
       "      <td>algérie emmanuel macron grande histoire amour</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>False</td>\n",
       "      <td>[algérie, emmanuel, macron, grande, histoire, ...</td>\n",
       "      <td>algérie emmanuel macron grande histoire amour</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353969 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  retweets_count  \\\n",
       "0                      rt refarcir macron ans nom prépare               3   \n",
       "1                                               populaire               0   \n",
       "2                                     faut dégager cinglé               3   \n",
       "3       enseignants mettre prescriptions président rép...               0   \n",
       "4                              mafieuse oppressive macron               0   \n",
       "...                                                   ...             ...   \n",
       "353964                     gonflette tour raciste frustré               0   \n",
       "353965  france caste crapuleuse encadrée gangsters irr...               0   \n",
       "353966                      eric zemmour français berbère               3   \n",
       "353967                           gauchistes dépression pq               0   \n",
       "353968      algérie emmanuel macron grande histoire amour               0   \n",
       "\n",
       "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
       "0                     0             3682          453535           3628   \n",
       "1                     0               86            1016            284   \n",
       "2                     1             1944           28234           1995   \n",
       "3                     0                1            1072              0   \n",
       "4                     0            13957           25311          10841   \n",
       "...                 ...              ...             ...            ...   \n",
       "353964                0               34            1509             55   \n",
       "353965                0               89           11166            127   \n",
       "353966                0             1888             712           3086   \n",
       "353967                0              139             486            320   \n",
       "353968                0                0              82             24   \n",
       "\n",
       "       mentions                         urls  verified hashtags  ...  \\\n",
       "0            []                           []         0       []  ...   \n",
       "1            []                           []         0       []  ...   \n",
       "2            []                           []         0       []  ...   \n",
       "3            []  ['https://t.co/rytlted08g']         0       []  ...   \n",
       "4            []                           []         0       []  ...   \n",
       "...         ...                          ...       ...      ...  ...   \n",
       "353964       []  ['https://t.co/pma33zhslx']         0       []  ...   \n",
       "353965       []                           []         0       []  ...   \n",
       "353966       []                           []         0       []  ...   \n",
       "353967       []                           []         0       []  ...   \n",
       "353968       []                           []         0       []  ...   \n",
       "\n",
       "        rep_chars_freq  max_char_freq  avg_word_count       log     rt  \\\n",
       "0             0.411765       0.205882               6 -2.302585   True   \n",
       "1             0.888889       0.222222               1 -2.302585  False   \n",
       "2             0.736842       0.157895               3  0.095310  False   \n",
       "3             0.170732       0.138211              14 -2.302585  False   \n",
       "4             0.538462       0.153846               3 -2.302585  False   \n",
       "...                ...            ...             ...       ...    ...   \n",
       "353964        0.500000       0.166667               4 -2.302585  False   \n",
       "353965        0.260870       0.159420               7 -2.302585  False   \n",
       "353966        0.551724       0.172414               4 -2.302585  False   \n",
       "353967        0.708333       0.166667               3 -2.302585  False   \n",
       "353968        0.377778       0.111111               6 -2.302585  False   \n",
       "\n",
       "                                                 text_arr  \\\n",
       "0               [rt, refarcir, macron, ans, nom, prépare]   \n",
       "1                                             [populaire]   \n",
       "2                                 [faut, dégager, cinglé]   \n",
       "3       [enseignants, mettre, prescriptions, président...   \n",
       "4                          [mafieuse, oppressive, macron]   \n",
       "...                                                   ...   \n",
       "353964                [gonflette, tour, raciste, frustré]   \n",
       "353965  [france, caste, crapuleuse, encadrée, gangster...   \n",
       "353966                 [eric, zemmour, français, berbère]   \n",
       "353967                       [gauchistes, dépression, pq]   \n",
       "353968  [algérie, emmanuel, macron, grande, histoire, ...   \n",
       "\n",
       "                                   text_without_stopwords  polarity  \\\n",
       "0                      rt refarcir macron ans nom prépare      0.00   \n",
       "1                                               populaire      0.50   \n",
       "2                                     faut dégager cinglé     -0.01   \n",
       "3       enseignants mettre prescriptions président rép...      0.06   \n",
       "4                              mafieuse oppressive macron      0.00   \n",
       "...                                                   ...       ...   \n",
       "353964                     gonflette tour raciste frustré      0.00   \n",
       "353965  france caste crapuleuse encadrée gangsters irr...      0.10   \n",
       "353966                      eric zemmour français berbère      0.20   \n",
       "353967                           gauchistes dépression pq      0.00   \n",
       "353968      algérie emmanuel macron grande histoire amour      0.30   \n",
       "\n",
       "        subjectivity     abrev  \n",
       "0              0.000  0.000000  \n",
       "1              0.500  0.000000  \n",
       "2             -0.010  0.000000  \n",
       "3              0.125  0.000000  \n",
       "4              0.000  0.000000  \n",
       "...              ...       ...  \n",
       "353964         0.000  0.000000  \n",
       "353965         0.200  0.000000  \n",
       "353966         0.000  0.000000  \n",
       "353967         0.000  0.333333  \n",
       "353968         0.200  0.000000  \n",
       "\n",
       "[353969 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = data.feature_words_arr(train_data)\n",
    "train_data = data.feature_delete_stop_words(train_data, 'text_without_stopwords')\n",
    "train_data = data.feature_sent_analysis(train_data, 'text_without_stopwords')\n",
    "train_data = data.feature_abbrev(train_data)\n",
    "display(train_data)\n",
    "# # outlier removal\n",
    "# train_data = train_data[train_data[\"retweets_count\"] <= 40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "# print(\"sentiment analysis...\")\n",
    "# train_data[\"compound\"] =  train_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful columns\n",
    "train_data_filtered = train_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\",\n",
    "                                        \"text_arr\", \"text_without_stopwords\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data_filtered = train_data.loc[:, [\"retweets_count\",\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\",\n",
    "#                                  \"hashtags_count\",\"hour\",\"verified\",\"url_count\",\"text_len\",\"rt\",\"Macron\",\"Zemmour\",\"Melenchon\"]]\n",
    "\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(train_data_filtered.drop(\"retweets_count\", axis=1),\n",
    "                                                    train_data_filtered[\"retweets_count\"],\n",
    "                                                    random_state=42, test_size=0.1)\n",
    "\n",
    "# Standardize the data\n",
    "normal_columns = train_data_filtered.drop([\"hour\", \"verified\", \"url_count\", \"rt\", \"retweets_count\"], axis=1).columns\n",
    "# normal_columns = train_data_filtered.drop([\"hour\", \"verified\", \"url_count\", \"rt\", \"retweets_count\"], axis=1).columns\n",
    "mu, sigma = X_train[normal_columns].mean(axis=0), X_train[normal_columns].std(axis=0)\n",
    "X_train.loc[:, normal_columns] = (X_train[normal_columns] - mu) / sigma\n",
    "X_eval.loc[:, normal_columns] = (X_eval[normal_columns] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:08:10.749437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(21, activation='relu'),\n",
    "  # tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(21, activation='relu'),\n",
    "  tf.keras.layers.Dense(21, activation='relu'),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 14.6442 - val_loss: 12.5955\n",
      "Epoch 2/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 9.1508 - val_loss: 6.7503\n",
      "Epoch 3/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.8084 - val_loss: 6.5639\n",
      "Epoch 4/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.6775 - val_loss: 6.5236\n",
      "Epoch 5/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.6163 - val_loss: 6.4130\n",
      "Epoch 6/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.5801 - val_loss: 6.3584\n",
      "Epoch 7/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.5347 - val_loss: 6.3735\n",
      "Epoch 8/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.4968 - val_loss: 6.3557\n",
      "Epoch 9/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.4754 - val_loss: 6.2737\n",
      "Epoch 10/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.4497 - val_loss: 6.2595\n",
      "Epoch 11/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.4210 - val_loss: 6.2175\n",
      "Epoch 12/75\n",
      "312/312 [==============================] - 0s 2ms/step - loss: 6.4049 - val_loss: 6.2086\n",
      "Epoch 13/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.3797 - val_loss: 6.1540\n",
      "Epoch 14/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.3667 - val_loss: 6.1667\n",
      "Epoch 15/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.3499 - val_loss: 6.1317\n",
      "Epoch 16/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.3295 - val_loss: 6.1001\n",
      "Epoch 17/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.3207 - val_loss: 6.0976\n",
      "Epoch 18/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.3100 - val_loss: 6.0993\n",
      "Epoch 19/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2953 - val_loss: 6.0807\n",
      "Epoch 20/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2886 - val_loss: 6.1192\n",
      "Epoch 21/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2736 - val_loss: 6.0692\n",
      "Epoch 22/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.2750 - val_loss: 6.0456\n",
      "Epoch 23/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2514 - val_loss: 6.0410\n",
      "Epoch 24/75\n",
      "312/312 [==============================] - 0s 2ms/step - loss: 6.2382 - val_loss: 6.0697\n",
      "Epoch 25/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2345 - val_loss: 6.0287\n",
      "Epoch 26/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2205 - val_loss: 6.0092\n",
      "Epoch 27/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.2103 - val_loss: 5.9985\n",
      "Epoch 28/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1973 - val_loss: 6.0017\n",
      "Epoch 29/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1983 - val_loss: 5.9595\n",
      "Epoch 30/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1850 - val_loss: 5.9899\n",
      "Epoch 31/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.1798 - val_loss: 6.0063\n",
      "Epoch 32/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1644 - val_loss: 5.9310\n",
      "Epoch 33/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1622 - val_loss: 5.9629\n",
      "Epoch 34/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1514 - val_loss: 5.9395\n",
      "Epoch 35/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1490 - val_loss: 5.8964\n",
      "Epoch 36/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1426 - val_loss: 5.9403\n",
      "Epoch 37/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.1357 - val_loss: 5.9182\n",
      "Epoch 38/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1282 - val_loss: 5.8739\n",
      "Epoch 39/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.1112 - val_loss: 5.9123\n",
      "Epoch 40/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.1090 - val_loss: 5.8920\n",
      "Epoch 41/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.1048 - val_loss: 5.8675\n",
      "Epoch 42/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0959 - val_loss: 5.8641\n",
      "Epoch 43/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0908 - val_loss: 5.8532\n",
      "Epoch 44/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0855 - val_loss: 5.8357\n",
      "Epoch 45/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0768 - val_loss: 5.8378\n",
      "Epoch 46/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0642 - val_loss: 5.8246\n",
      "Epoch 47/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0657 - val_loss: 5.8725\n",
      "Epoch 48/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.0612 - val_loss: 5.8350\n",
      "Epoch 49/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 6.0483 - val_loss: 5.7981\n",
      "Epoch 50/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0373 - val_loss: 5.8025\n",
      "Epoch 51/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0339 - val_loss: 5.8197\n",
      "Epoch 52/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0396 - val_loss: 5.7780\n",
      "Epoch 53/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0249 - val_loss: 5.8050\n",
      "Epoch 54/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0186 - val_loss: 5.7958\n",
      "Epoch 55/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 6.0237 - val_loss: 5.7835\n",
      "Epoch 56/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 6.0078 - val_loss: 5.8166\n",
      "Epoch 57/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.9976 - val_loss: 5.7850\n",
      "Epoch 58/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9987 - val_loss: 5.7750\n",
      "Epoch 59/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9937 - val_loss: 5.7643\n",
      "Epoch 60/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9909 - val_loss: 5.7898\n",
      "Epoch 61/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9869 - val_loss: 5.7573\n",
      "Epoch 62/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9788 - val_loss: 5.7501\n",
      "Epoch 63/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9759 - val_loss: 5.7791\n",
      "Epoch 64/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9689 - val_loss: 5.7739\n",
      "Epoch 65/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.9612 - val_loss: 5.7560\n",
      "Epoch 66/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9707 - val_loss: 5.7320\n",
      "Epoch 67/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9574 - val_loss: 5.7647\n",
      "Epoch 68/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9605 - val_loss: 5.7425\n",
      "Epoch 69/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9354 - val_loss: 5.7505\n",
      "Epoch 70/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9409 - val_loss: 5.7383\n",
      "Epoch 71/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9334 - val_loss: 5.7343\n",
      "Epoch 72/75\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 5.9333 - val_loss: 5.7351\n",
      "Epoch 73/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.9291 - val_loss: 5.7094\n",
      "Epoch 74/75\n",
      "312/312 [==============================] - 0s 1ms/step - loss: 5.9091 - val_loss: 5.7591\n",
      "Epoch 75/75\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 5.9029 - val_loss: 5.7810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values.astype(np.float32), y_train.values.astype(np.float32), epochs=75, batch_size=1024,\n",
    "         validation_data=(X_eval.values.astype(np.float32), y_eval.values.astype(np.float32)), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"loss\"], 'b', label='Training loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], 'g', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107/1107 - 1s - loss: 5.6089 - 519ms/epoch - 468us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.608860015869141"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_eval.values.astype(np.float32),  y_eval.values.astype(np.float32), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107/1107 [==============================] - 1s 541us/step\n",
      "[[1.1453982e-02]\n",
      " [7.2697364e-03]\n",
      " [6.8483740e-01]\n",
      " ...\n",
      " [1.4571663e-02]\n",
      " [1.7139431e-02]\n",
      " [1.5089805e+01]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_eval.values.astype(np.float32))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = X_eval.copy()\n",
    "eval_data [\"groundtruth\"] = y_eval\n",
    "eval_data[\"pred\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>log</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>rt</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>abrev</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307625</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077407</td>\n",
       "      <td>-0.334165</td>\n",
       "      <td>-0.497254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.731841</td>\n",
       "      <td>-0.170714</td>\n",
       "      <td>-1.877710</td>\n",
       "      <td>-0.995912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145207</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.794312</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52950</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077779</td>\n",
       "      <td>-0.408998</td>\n",
       "      <td>-0.502035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376416</td>\n",
       "      <td>-0.417564</td>\n",
       "      <td>-1.208763</td>\n",
       "      <td>1.026855</td>\n",
       "      <td>-2.341159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339408</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989324</td>\n",
       "      <td>0.480421</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289882</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.067681</td>\n",
       "      <td>2.979071</td>\n",
       "      <td>1.399853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691572</td>\n",
       "      <td>-0.655960</td>\n",
       "      <td>0.224789</td>\n",
       "      <td>-1.033007</td>\n",
       "      <td>2.179209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145207</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.459153</td>\n",
       "      <td>0.963819</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17637</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.075549</td>\n",
       "      <td>0.847381</td>\n",
       "      <td>-0.566985</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.076841</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.848256</td>\n",
       "      <td>-0.417382</td>\n",
       "      <td>0.304030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145207</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>True</td>\n",
       "      <td>0.144274</td>\n",
       "      <td>0.534132</td>\n",
       "      <td>2.679304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339255</th>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.028786</td>\n",
       "      <td>-0.027463</td>\n",
       "      <td>0.115989</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.058760</td>\n",
       "      <td>-0.127474</td>\n",
       "      <td>0.371056</td>\n",
       "      <td>0.482839</td>\n",
       "      <td>-2.084839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048994</td>\n",
       "      <td>0.474196</td>\n",
       "      <td>1.663403</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308634</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.071539</td>\n",
       "      <td>0.205442</td>\n",
       "      <td>0.380173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380697</td>\n",
       "      <td>0.716708</td>\n",
       "      <td>-1.005423</td>\n",
       "      <td>-0.727449</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.214200</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>3</td>\n",
       "      <td>0.813151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276530</th>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.077630</td>\n",
       "      <td>-0.393446</td>\n",
       "      <td>-0.539890</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.526453</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>1.052789</td>\n",
       "      <td>0.868463</td>\n",
       "      <td>-0.749671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533609</td>\n",
       "      <td>0.474196</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216501</td>\n",
       "      <td>-0.110400</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>3</td>\n",
       "      <td>1.122044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302150</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.076848</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>-0.174096</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.299950</td>\n",
       "      <td>-0.032991</td>\n",
       "      <td>-0.322349</td>\n",
       "      <td>-0.525828</td>\n",
       "      <td>0.733617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437396</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.397424</td>\n",
       "      <td>-0.325244</td>\n",
       "      <td>1.802425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55651</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077729</td>\n",
       "      <td>-0.401657</td>\n",
       "      <td>-0.502434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435267</td>\n",
       "      <td>-0.361918</td>\n",
       "      <td>-0.277946</td>\n",
       "      <td>-0.782868</td>\n",
       "      <td>-0.698079</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.019999</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194022</th>\n",
       "      <td>-0.008948</td>\n",
       "      <td>0.402570</td>\n",
       "      <td>0.433283</td>\n",
       "      <td>0.017169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731044</td>\n",
       "      <td>-0.642071</td>\n",
       "      <td>1.417026</td>\n",
       "      <td>0.601983</td>\n",
       "      <td>-0.384656</td>\n",
       "      <td>...</td>\n",
       "      <td>2.281418</td>\n",
       "      <td>2.020930</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.913486</td>\n",
       "      <td>0.748976</td>\n",
       "      <td>-0.389772</td>\n",
       "      <td>13</td>\n",
       "      <td>15.089805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35397 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
       "307625        -0.055089        -0.077407       -0.334165      -0.497254   \n",
       "52950         -0.055089        -0.077779       -0.408998      -0.502035   \n",
       "289882        -0.055089        -0.067681        2.979071       1.399853   \n",
       "17637         -0.055089        -0.075549        0.847381      -0.566985   \n",
       "339255        -0.053906        -0.028786       -0.027463       0.115989   \n",
       "...                 ...              ...             ...            ...   \n",
       "308634        -0.055089        -0.071539        0.205442       0.380173   \n",
       "276530        -0.053906        -0.077630       -0.393446      -0.539890   \n",
       "302150        -0.055089        -0.076848       -0.012975      -0.174096   \n",
       "55651         -0.055089        -0.077729       -0.401657      -0.502434   \n",
       "194022        -0.008948         0.402570        0.433283       0.017169   \n",
       "\n",
       "        verified         0         1         2         3         4  ...  \\\n",
       "307625         0  0.008149  0.731841 -0.170714 -1.877710 -0.995912  ...   \n",
       "52950          0  0.376416 -0.417564 -1.208763  1.026855 -2.341159  ...   \n",
       "289882         0  0.691572 -0.655960  0.224789 -1.033007  2.179209  ...   \n",
       "17637          0 -0.076841  0.729537  0.848256 -0.417382  0.304030  ...   \n",
       "339255         0 -0.058760 -0.127474  0.371056  0.482839 -2.084839  ...   \n",
       "...          ...       ...       ...       ...       ...       ...  ...   \n",
       "308634         0  0.380697  0.716708 -1.005423 -0.727449  0.030930  ...   \n",
       "276530         0 -0.526453  0.082621  1.052789  0.868463 -0.749671  ...   \n",
       "302150         0 -0.299950 -0.032991 -0.322349 -0.525828  0.733617  ...   \n",
       "55651          0  0.435267 -0.361918 -0.277946 -0.782868 -0.698079  ...   \n",
       "194022         1  0.731044 -0.642071  1.417026  0.601983 -0.384656  ...   \n",
       "\n",
       "        avg_word_count       log    Macron   Zemmour     rt  polarity  \\\n",
       "307625        0.145207 -0.564477 -0.601175 -0.379343  False  0.794312   \n",
       "52950         0.339408 -0.564477 -0.601175 -0.379343  False  0.989324   \n",
       "289882        0.145207 -0.564477 -0.601175 -0.379343   True -1.459153   \n",
       "17637         0.145207 -0.564477 -0.601175 -0.379343   True  0.144274   \n",
       "339255       -0.048994  0.474196  1.663403 -0.379343  False -0.072405   \n",
       "...                ...       ...       ...       ...    ...       ...   \n",
       "308634       -1.214200 -0.564477 -0.601175 -0.379343  False -0.072405   \n",
       "276530        0.533609  0.474196 -0.601175 -0.379343  False  0.216501   \n",
       "302150       -0.437396 -0.564477 -0.601175 -0.379343  False -0.397424   \n",
       "55651        -1.019999 -0.564477 -0.601175 -0.379343  False -0.072405   \n",
       "194022        2.281418  2.020930 -0.601175 -0.379343  False  0.913486   \n",
       "\n",
       "        subjectivity     abrev  groundtruth       pred  \n",
       "307625     -0.754931 -0.389772            0   0.011454  \n",
       "52950       0.480421 -0.389772            0   0.007270  \n",
       "289882      0.963819 -0.389772            0   0.684837  \n",
       "17637       0.534132  2.679304            0   0.004103  \n",
       "339255     -0.754931 -0.389772            1   1.240436  \n",
       "...              ...       ...          ...        ...  \n",
       "308634     -0.754931 -0.389772            3   0.813151  \n",
       "276530     -0.110400 -0.389772            3   1.122044  \n",
       "302150     -0.325244  1.802425            0   0.014572  \n",
       "55651      -0.754931 -0.389772            0   0.017139  \n",
       "194022      0.748976 -0.389772           13  15.089805  \n",
       "\n",
       "[35397 rows x 56 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data.to_csv(\"pred_example_58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[\"favorites_count\"], model.predict(X_train))\n",
    "# plt.scatter(X_train[\"favorites_count\"], y_train.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "eval_data = pd.read_csv(\"data/evaluation_with_embeddings.csv\")\n",
    "eval_data = eval_data.drop([\"Unnamed: 0\"], axis=1)\n",
    "tweets = eval_data[\"TweetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>rep_chars_freq</th>\n",
       "      <th>max_char_freq</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>log</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>rt</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077561</td>\n",
       "      <td>-0.384487</td>\n",
       "      <td>-0.451430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627411</td>\n",
       "      <td>-0.188243</td>\n",
       "      <td>-1.069439</td>\n",
       "      <td>-0.627192</td>\n",
       "      <td>-0.398087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110779</td>\n",
       "      <td>2.917037</td>\n",
       "      <td>-1.214200</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.076250</td>\n",
       "      <td>-0.130940</td>\n",
       "      <td>-0.405207</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>0.682637</td>\n",
       "      <td>-0.716718</td>\n",
       "      <td>-0.610757</td>\n",
       "      <td>1.009279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251218</td>\n",
       "      <td>-0.457844</td>\n",
       "      <td>-1.019999</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.047990</td>\n",
       "      <td>-0.073569</td>\n",
       "      <td>-0.308274</td>\n",
       "      <td>0.054226</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>0.635851</td>\n",
       "      <td>-0.348722</td>\n",
       "      <td>-0.520216</td>\n",
       "      <td>0.882950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329674</td>\n",
       "      <td>0.111941</td>\n",
       "      <td>-0.631597</td>\n",
       "      <td>1.216190</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>1.393507</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052722</td>\n",
       "      <td>-0.071378</td>\n",
       "      <td>-0.197070</td>\n",
       "      <td>0.229552</td>\n",
       "      <td>0</td>\n",
       "      <td>1.204404</td>\n",
       "      <td>-3.270518</td>\n",
       "      <td>1.816433</td>\n",
       "      <td>2.189510</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044832</td>\n",
       "      <td>-0.390242</td>\n",
       "      <td>1.310413</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>1.663403</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.939123</td>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.569314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.076932</td>\n",
       "      <td>-0.241396</td>\n",
       "      <td>-0.434694</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.208759</td>\n",
       "      <td>-0.901484</td>\n",
       "      <td>1.551472</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>1.186333</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017076</td>\n",
       "      <td>-0.578708</td>\n",
       "      <td>1.504614</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>2.636129</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.289085</td>\n",
       "      <td>0.405225</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117985</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077871</td>\n",
       "      <td>-0.421834</td>\n",
       "      <td>-0.556227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249026</td>\n",
       "      <td>0.352226</td>\n",
       "      <td>-0.638636</td>\n",
       "      <td>-0.657624</td>\n",
       "      <td>-0.304555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886078</td>\n",
       "      <td>0.111941</td>\n",
       "      <td>-1.019999</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117986</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.075036</td>\n",
       "      <td>-0.076371</td>\n",
       "      <td>-0.225498</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.190405</td>\n",
       "      <td>-0.782128</td>\n",
       "      <td>-1.860208</td>\n",
       "      <td>0.260190</td>\n",
       "      <td>-0.092876</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027759</td>\n",
       "      <td>-0.705406</td>\n",
       "      <td>1.698815</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117987</th>\n",
       "      <td>-0.040891</td>\n",
       "      <td>-0.074347</td>\n",
       "      <td>-0.403582</td>\n",
       "      <td>-0.518372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.220602</td>\n",
       "      <td>-1.257055</td>\n",
       "      <td>0.863901</td>\n",
       "      <td>-1.019101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574482</td>\n",
       "      <td>-0.223227</td>\n",
       "      <td>0.145207</td>\n",
       "      <td>1.512869</td>\n",
       "      <td>1.663403</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.480821</td>\n",
       "      <td>1.393507</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117988</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077867</td>\n",
       "      <td>-0.423504</td>\n",
       "      <td>-0.549851</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.926892</td>\n",
       "      <td>-1.348052</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>2.060643</td>\n",
       "      <td>-0.080239</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.004058</td>\n",
       "      <td>0.480625</td>\n",
       "      <td>1.504614</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>2.094389</td>\n",
       "      <td>3.112258</td>\n",
       "      <td>0.512898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117989</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.075760</td>\n",
       "      <td>-0.373401</td>\n",
       "      <td>-0.522357</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.628546</td>\n",
       "      <td>-0.797480</td>\n",
       "      <td>-1.768613</td>\n",
       "      <td>0.931430</td>\n",
       "      <td>-0.642227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.519206</td>\n",
       "      <td>-0.243195</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>True</td>\n",
       "      <td>1.704366</td>\n",
       "      <td>0.534132</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117990 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
       "0             -0.055089        -0.077561       -0.384487      -0.451430   \n",
       "1             -0.055089        -0.076250       -0.130940      -0.405207   \n",
       "2             -0.047990        -0.073569       -0.308274       0.054226   \n",
       "3             -0.052722        -0.071378       -0.197070       0.229552   \n",
       "4             -0.055089        -0.076932       -0.241396      -0.434694   \n",
       "...                 ...              ...             ...            ...   \n",
       "117985        -0.055089        -0.077871       -0.421834      -0.556227   \n",
       "117986        -0.055089        -0.075036       -0.076371      -0.225498   \n",
       "117987        -0.040891        -0.074347       -0.403582      -0.518372   \n",
       "117988        -0.055089        -0.077867       -0.423504      -0.549851   \n",
       "117989        -0.055089        -0.075760       -0.373401      -0.522357   \n",
       "\n",
       "        verified         0         1         2         3         4  ...  \\\n",
       "0              0  0.627411 -0.188243 -1.069439 -0.627192 -0.398087  ...   \n",
       "1              0 -0.000590  0.682637 -0.716718 -0.610757  1.009279  ...   \n",
       "2              0 -0.004098  0.635851 -0.348722 -0.520216  0.882950  ...   \n",
       "3              0  1.204404 -3.270518  1.816433  2.189510 -0.580318  ...   \n",
       "4              0 -1.208759 -0.901484  1.551472  0.123558  1.186333  ...   \n",
       "...          ...       ...       ...       ...       ...       ...  ...   \n",
       "117985         0  0.249026  0.352226 -0.638636 -0.657624 -0.304555  ...   \n",
       "117986         0 -0.190405 -0.782128 -1.860208  0.260190 -0.092876  ...   \n",
       "117987         0  0.521246  0.220602 -1.257055  0.863901 -1.019101  ...   \n",
       "117988         0 -0.926892 -1.348052  0.007385  2.060643 -0.080239  ...   \n",
       "117989         0 -0.628546 -0.797480 -1.768613  0.931430 -0.642227  ...   \n",
       "\n",
       "        rep_chars_freq  max_char_freq  avg_word_count       log    Macron  \\\n",
       "0             1.110779       2.917037       -1.214200 -0.564477 -0.601175   \n",
       "1             1.251218      -0.457844       -1.019999 -0.564477 -0.601175   \n",
       "2             0.329674       0.111941       -0.631597  1.216190 -0.601175   \n",
       "3            -1.044832      -0.390242        1.310413  0.754289  1.663403   \n",
       "4            -1.017076      -0.578708        1.504614 -0.564477 -0.601175   \n",
       "...                ...            ...             ...       ...       ...   \n",
       "117985        0.886078       0.111941       -1.019999 -0.564477 -0.601175   \n",
       "117986       -1.027759      -0.705406        1.698815 -0.564477 -0.601175   \n",
       "117987       -0.574482      -0.223227        0.145207  1.512869  1.663403   \n",
       "117988       -1.004058       0.480625        1.504614 -0.564477 -0.601175   \n",
       "117989       -0.237430      -0.519206       -0.243195 -0.564477 -0.601175   \n",
       "\n",
       "         Zemmour     rt  polarity  subjectivity     abrev  \n",
       "0      -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "1      -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "2      -0.379343  False -0.072405      1.393507 -0.389772  \n",
       "3      -0.379343  False -0.939123      0.319288  0.569314  \n",
       "4       2.636129  False -0.289085      0.405225 -0.389772  \n",
       "...          ...    ...       ...           ...       ...  \n",
       "117985 -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "117986 -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "117987 -0.379343  False -1.480821      1.393507 -0.389772  \n",
       "117988 -0.379343  False  2.094389      3.112258  0.512898  \n",
       "117989 -0.379343   True  1.704366      0.534132 -0.389772  \n",
       "\n",
       "[117990 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_data[\"url_count\"] = eval_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"text_len\"] = eval_data[\"text\"].apply(lambda s: len(s))\n",
    "eval_data[\"hashtags_count\"] = eval_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"day\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "eval_data[\"hour\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "# eval_data[\"Macron\"] =  eval_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "# eval_data[\"Zemmour\"] =  eval_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "# eval_data[\"Melenchon\"] =  eval_data[\"text\"].apply(lambda s: (\"melenchon\" in s.lower().split()))\n",
    "eval_data[\"avg_word_len\"] = eval_data[\"text\"].apply(lambda s: np.mean([len(w) for w in s.split()]))\n",
    "eval_data[\"rep_words_freq\"] = eval_data[\"text\"].apply(lambda s: np.mean(len(list(set(s.split())))/len(s.split())))\n",
    "eval_data[\"rep_chars_freq\"] = eval_data[\"text\"].apply(lambda s: np.mean(len(list(set(s)))/len(list(s))))\n",
    "eval_data[\"max_char_freq\"] = eval_data[\"text\"].apply(lambda s: max( [s.count(c) for c in list(set(s))] )/len(list(s)))\n",
    "eval_data[\"avg_word_count\"] = eval_data[\"text\"].apply(lambda s: len(s.split()))\n",
    "\n",
    "eval_data[\"log\"] = np.log(0.1 + eval_data[\"favorites_count\"])\n",
    "\n",
    "# indicators of keywords\n",
    "eval_data[\"Macron\"] =  eval_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "eval_data[\"Zemmour\"] =  eval_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "# eval_data[\"Melenchon\"] =  eval_data[\"text\"].apply(lambda s: (\"melenchon\" in s.replace(\"é\",\"e\").lower().split()))\n",
    "eval_data[\"rt\"] =  eval_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))\n",
    "\n",
    "# print(\"sentiment analysis...\")\n",
    "# eval_data[\"compound\"] =  eval_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])\n",
    "\n",
    "eval_data = data.feature_words_arr(eval_data)\n",
    "eval_data = data.feature_delete_stop_words(eval_data, 'text_without_stopwords')\n",
    "eval_data = data.feature_sent_analysis(eval_data, 'text_without_stopwords')\n",
    "eval_data = data.feature_abbrev(eval_data)\n",
    "\n",
    "eval_data = eval_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\",\n",
    "                                        \"text_arr\", \"text_without_stopwords\"], axis=1)\n",
    "\n",
    "# normalize\n",
    "eval_data.loc[:, normal_columns] = (eval_data.loc[:, normal_columns] - mu) / sigma\n",
    "\n",
    "display(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>rep_chars_freq</th>\n",
       "      <th>max_char_freq</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>log</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>rt</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286184</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077844</td>\n",
       "      <td>-0.421579</td>\n",
       "      <td>-0.525943</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.454199</td>\n",
       "      <td>-0.479638</td>\n",
       "      <td>-0.839479</td>\n",
       "      <td>-0.937126</td>\n",
       "      <td>1.109783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026925</td>\n",
       "      <td>-0.066815</td>\n",
       "      <td>-0.243195</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83577</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.067811</td>\n",
       "      <td>-0.070867</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.049611</td>\n",
       "      <td>-1.883312</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.632474</td>\n",
       "      <td>-0.894389</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000478</td>\n",
       "      <td>-0.125469</td>\n",
       "      <td>0.533609</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.924320</td>\n",
       "      <td>-0.038785</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165861</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.077714</td>\n",
       "      <td>-0.417499</td>\n",
       "      <td>-0.523552</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.515792</td>\n",
       "      <td>-0.471596</td>\n",
       "      <td>-0.023280</td>\n",
       "      <td>-0.515503</td>\n",
       "      <td>0.730691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301854</td>\n",
       "      <td>1.226187</td>\n",
       "      <td>-0.631597</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314938</th>\n",
       "      <td>-0.045624</td>\n",
       "      <td>-0.071025</td>\n",
       "      <td>-0.322850</td>\n",
       "      <td>-0.292042</td>\n",
       "      <td>0</td>\n",
       "      <td>1.506209</td>\n",
       "      <td>-0.835940</td>\n",
       "      <td>-0.163854</td>\n",
       "      <td>-0.338194</td>\n",
       "      <td>1.489977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640871</td>\n",
       "      <td>-0.095254</td>\n",
       "      <td>0.727810</td>\n",
       "      <td>1.339024</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.394150</td>\n",
       "      <td>1.715773</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301981</th>\n",
       "      <td>-0.052722</td>\n",
       "      <td>-0.076427</td>\n",
       "      <td>-0.310814</td>\n",
       "      <td>-0.221115</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>-0.743971</td>\n",
       "      <td>1.567646</td>\n",
       "      <td>0.206960</td>\n",
       "      <td>0.283644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.222545</td>\n",
       "      <td>-1.276674</td>\n",
       "      <td>1.310413</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.490961</td>\n",
       "      <td>0.383741</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.074569</td>\n",
       "      <td>-0.374245</td>\n",
       "      <td>-0.252993</td>\n",
       "      <td>0</td>\n",
       "      <td>1.221808</td>\n",
       "      <td>0.319591</td>\n",
       "      <td>0.832282</td>\n",
       "      <td>-0.891572</td>\n",
       "      <td>1.490662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119553</td>\n",
       "      <td>0.261393</td>\n",
       "      <td>-0.437396</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.067190</td>\n",
       "      <td>-0.409402</td>\n",
       "      <td>-0.420349</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.331935</td>\n",
       "      <td>0.591412</td>\n",
       "      <td>-0.061578</td>\n",
       "      <td>0.488688</td>\n",
       "      <td>-0.477316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195818</td>\n",
       "      <td>-0.310122</td>\n",
       "      <td>-0.243195</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>1.663403</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.372482</td>\n",
       "      <td>1.393507</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.062559</td>\n",
       "      <td>-0.417992</td>\n",
       "      <td>0.397706</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.084263</td>\n",
       "      <td>-1.102450</td>\n",
       "      <td>-0.089161</td>\n",
       "      <td>1.266020</td>\n",
       "      <td>-0.328144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671853</td>\n",
       "      <td>-0.546477</td>\n",
       "      <td>0.533609</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072405</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>0.889010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>-0.055089</td>\n",
       "      <td>-0.076515</td>\n",
       "      <td>-0.175583</td>\n",
       "      <td>-0.372135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574601</td>\n",
       "      <td>-3.972517</td>\n",
       "      <td>-1.152867</td>\n",
       "      <td>0.601042</td>\n",
       "      <td>0.571519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999184</td>\n",
       "      <td>0.079613</td>\n",
       "      <td>2.281418</td>\n",
       "      <td>-0.564477</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>2.636129</td>\n",
       "      <td>False</td>\n",
       "      <td>2.744427</td>\n",
       "      <td>1.823195</td>\n",
       "      <td>0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.069167</td>\n",
       "      <td>0.454136</td>\n",
       "      <td>0.273384</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.080712</td>\n",
       "      <td>-1.410317</td>\n",
       "      <td>0.326710</td>\n",
       "      <td>1.792768</td>\n",
       "      <td>-0.734769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278987</td>\n",
       "      <td>-0.504768</td>\n",
       "      <td>2.475619</td>\n",
       "      <td>0.474196</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.379343</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>0.176059</td>\n",
       "      <td>-0.389772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318572 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
       "286184        -0.055089        -0.077844       -0.421579      -0.525943   \n",
       "83577         -0.055089        -0.067811       -0.070867       0.325185   \n",
       "165861        -0.055089        -0.077714       -0.417499      -0.523552   \n",
       "314938        -0.045624        -0.071025       -0.322850      -0.292042   \n",
       "301981        -0.052722        -0.076427       -0.310814      -0.221115   \n",
       "...                 ...              ...             ...            ...   \n",
       "119879        -0.055089        -0.074569       -0.374245      -0.252993   \n",
       "259178        -0.055089        -0.067190       -0.409402      -0.420349   \n",
       "131932        -0.055089        -0.062559       -0.417992       0.397706   \n",
       "146867        -0.055089        -0.076515       -0.175583      -0.372135   \n",
       "121958        -0.053906        -0.069167        0.454136       0.273384   \n",
       "\n",
       "        verified         0         1         2         3         4  ...  \\\n",
       "286184         0 -0.454199 -0.479638 -0.839479 -0.937126  1.109783  ...   \n",
       "83577          0 -0.049611 -1.883312  0.014960  0.632474 -0.894389  ...   \n",
       "165861         0 -0.515792 -0.471596 -0.023280 -0.515503  0.730691  ...   \n",
       "314938         0  1.506209 -0.835940 -0.163854 -0.338194  1.489977  ...   \n",
       "301981         0  0.193906 -0.743971  1.567646  0.206960  0.283644  ...   \n",
       "...          ...       ...       ...       ...       ...       ...  ...   \n",
       "119879         0  1.221808  0.319591  0.832282 -0.891572  1.490662  ...   \n",
       "259178         0 -0.331935  0.591412 -0.061578  0.488688 -0.477316  ...   \n",
       "131932         0 -0.084263 -1.102450 -0.089161  1.266020 -0.328144  ...   \n",
       "146867         0  0.574601 -3.972517 -1.152867  0.601042  0.571519  ...   \n",
       "121958         0 -0.080712 -1.410317  0.326710  1.792768 -0.734769  ...   \n",
       "\n",
       "        rep_chars_freq  max_char_freq  avg_word_count       log    Macron  \\\n",
       "286184        0.026925      -0.066815       -0.243195 -0.564477 -0.601175   \n",
       "83577        -1.000478      -0.125469        0.533609 -0.564477 -0.601175   \n",
       "165861        0.301854       1.226187       -0.631597 -0.564477 -0.601175   \n",
       "314938       -0.640871      -0.095254        0.727810  1.339024 -0.601175   \n",
       "301981       -1.222545      -1.276674        1.310413  0.754289 -0.601175   \n",
       "...                ...            ...             ...       ...       ...   \n",
       "119879       -0.119553       0.261393       -0.437396 -0.564477 -0.601175   \n",
       "259178       -0.195818      -0.310122       -0.243195 -0.564477  1.663403   \n",
       "131932       -0.671853      -0.546477        0.533609 -0.564477 -0.601175   \n",
       "146867       -0.999184       0.079613        2.281418 -0.564477 -0.601175   \n",
       "121958       -1.278987      -0.504768        2.475619  0.474196 -0.601175   \n",
       "\n",
       "         Zemmour     rt  polarity  subjectivity     abrev  \n",
       "286184 -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "83577  -0.379343  False  0.924320     -0.038785 -0.389772  \n",
       "165861 -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "314938 -0.379343  False -1.394150      1.715773 -0.389772  \n",
       "301981 -0.379343  False  0.490961      0.383741 -0.389772  \n",
       "...          ...    ...       ...           ...       ...  \n",
       "119879 -0.379343  False -0.072405     -0.754931 -0.389772  \n",
       "259178 -0.379343  False -1.372482      1.393507 -0.389772  \n",
       "131932 -0.379343  False -0.072405     -0.754931  0.889010  \n",
       "146867  2.636129  False  2.744427      1.823195  0.340960  \n",
       "121958 -0.379343  False  0.072048      0.176059 -0.389772  \n",
       "\n",
       "[318572 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3688/3688 [==============================] - 2s 475us/step\n",
      "[[ 1.2847360e-02]\n",
      " [ 8.3314143e-03]\n",
      " [ 2.5101335e+00]\n",
      " ...\n",
      " [ 4.1257033e+00]\n",
      " [ 1.4819022e-02]\n",
      " [-1.1770763e-03]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(eval_data.values.astype(np.float32))\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# output normalization\n",
    "for i,p in enumerate(pred):\n",
    "    if p<0: pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/predictions.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"retweets_count\"])\n",
    "    for index, prediction in enumerate(pred):\n",
    "        writer.writerow([str(tweets[index]) , str(int(prediction))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

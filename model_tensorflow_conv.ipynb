{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 22:38:27.116252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 22:38:27.324284: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-04 22:38:27.959096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 22:38:27.959151: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 22:38:27.959156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 22:38:28.644440: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2022-12-04 22:38:28.644492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: danilo-Nitro-AN515-58\n",
      "2022-12-04 22:38:28.644530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: danilo-Nitro-AN515-58\n",
      "2022-12-04 22:38:28.644725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2022-12-04 22:38:28.644759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.60.11\n",
      "2022-12-04 22:38:28.644766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 525.60.11 does not match DSO version 510.108.3 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features\n",
    "train_data[\"url_count\"] = train_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"text_len\"] = train_data[\"text\"].apply(lambda s: len(s))\n",
    "train_data[\"hashtags_count\"] = train_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "train_data[\"day\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "train_data[\"hour\"] = train_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "\n",
    "# indicators of keywords\n",
    "train_data[\"Macron\"] =  train_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "train_data[\"Zemmour\"] =  train_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "train_data[\"Melenchon\"] =  train_data[\"text\"].apply(lambda s: (\"melenchon\" in s.replace(\"Ã©\",\"e\").lower().split()))\n",
    "train_data[\"rt\"] =  train_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target\n",
    "target = train_data[\"retweets_count\"]\n",
    "train_data = train_data.drop([\"retweets_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful columns\n",
    "train_data_filtered = train_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "normal_columns = train_data_filtered.drop([\"hour\", \"verified\", \"Macron\", \"Zemmour\", \"Melenchon\", \"url_count\", \"rt\"], axis=1).columns\n",
    "mu, sigma = train_data_filtered[normal_columns].mean(axis=0), train_data_filtered[normal_columns].std(axis=0)\n",
    "train_data_filtered.loc[:, normal_columns] = (train_data_filtered[normal_columns] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>url_count</th>\n",
       "      <th>text_len</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>Macron</th>\n",
       "      <th>Zemmour</th>\n",
       "      <th>Melenchon</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.063622</td>\n",
       "      <td>3.575856</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.865385</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>-1.030050</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077459</td>\n",
       "      <td>-0.415125</td>\n",
       "      <td>-0.469565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.466000</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>1.385496</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.053583</td>\n",
       "      <td>-0.070310</td>\n",
       "      <td>-0.175076</td>\n",
       "      <td>0.214033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.225754</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>0.177723</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077786</td>\n",
       "      <td>-0.414631</td>\n",
       "      <td>-0.583032</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.272804</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>-0.124220</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.024083</td>\n",
       "      <td>-0.200855</td>\n",
       "      <td>3.748287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.057582</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>-0.124220</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353964</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.410777</td>\n",
       "      <td>-0.561057</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.961483</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>0.479666</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353965</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077448</td>\n",
       "      <td>-0.325607</td>\n",
       "      <td>-0.532291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024524</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>-0.728107</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353966</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.070525</td>\n",
       "      <td>-0.417806</td>\n",
       "      <td>0.649922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.985508</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>1.083553</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353967</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077255</td>\n",
       "      <td>-0.419799</td>\n",
       "      <td>-0.455182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.105631</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>-1.030050</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353968</th>\n",
       "      <td>-0.054757</td>\n",
       "      <td>-0.077790</td>\n",
       "      <td>-0.423362</td>\n",
       "      <td>-0.573443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.601114</td>\n",
       "      <td>-0.384248</td>\n",
       "      <td>1.083553</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353969 rows Ã 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
       "0             -0.054757        -0.063622        3.575856       0.866468   \n",
       "1             -0.054757        -0.077459       -0.415125      -0.469565   \n",
       "2             -0.053583        -0.070310       -0.175076       0.214033   \n",
       "3             -0.054757        -0.077786       -0.414631      -0.583032   \n",
       "4             -0.054757        -0.024083       -0.200855       3.748287   \n",
       "...                 ...              ...             ...            ...   \n",
       "353964        -0.054757        -0.077659       -0.410777      -0.561057   \n",
       "353965        -0.054757        -0.077448       -0.325607      -0.532291   \n",
       "353966        -0.054757        -0.070525       -0.417806       0.649922   \n",
       "353967        -0.054757        -0.077255       -0.419799      -0.455182   \n",
       "353968        -0.054757        -0.077790       -0.423362      -0.573443   \n",
       "\n",
       "        verified  url_count  text_len  hashtags_count       day  hour  Macron  \\\n",
       "0              0        0.0 -0.865385       -0.384248 -1.030050     5    True   \n",
       "1              0        0.0 -1.466000       -0.384248  1.385496    12   False   \n",
       "2              0        0.0 -1.225754       -0.384248  0.177723    18   False   \n",
       "3              0        1.0  1.272804       -0.384248 -0.124220    11   False   \n",
       "4              0        0.0 -1.057582       -0.384248 -0.124220    11    True   \n",
       "...          ...        ...       ...             ...       ...   ...     ...   \n",
       "353964         0        1.0 -0.961483       -0.384248  0.479666    13   False   \n",
       "353965         0        0.0 -0.024524       -0.384248 -0.728107     8   False   \n",
       "353966         0        0.0 -0.985508       -0.384248  1.083553    12   False   \n",
       "353967         0        0.0 -1.105631       -0.384248 -1.030050     8   False   \n",
       "353968         0        0.0 -0.601114       -0.384248  1.083553    11    True   \n",
       "\n",
       "        Zemmour  Melenchon     rt  \n",
       "0         False      False   True  \n",
       "1         False      False  False  \n",
       "2         False      False  False  \n",
       "3         False      False  False  \n",
       "4         False      False  False  \n",
       "...         ...        ...    ...  \n",
       "353964    False      False  False  \n",
       "353965    False      False  False  \n",
       "353966     True      False  False  \n",
       "353967    False      False  False  \n",
       "353968    False      False  False  \n",
       "\n",
       "[353969 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353969, 14) (353969, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "emb_matrix = np.load(\"data/train_emb_matrix.npy\")\n",
    "print(train_data_filtered.shape, emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05475705537294453, -0.06362175216471, 3.575856294985138,\n",
       "        0.8664677648458644, 0, 0.0, -0.865384899170238,\n",
       "        -0.3842477354707097, -1.0300503271633217, 5, True, False, False,\n",
       "        True],\n",
       "       [-0.05475705537294453, -0.06362175216471, 3.575856294985138,\n",
       "        0.8664677648458644, 0, 0.0, -0.865384899170238,\n",
       "        -0.3842477354707097, -1.0300503271633217, 5, True, False, False,\n",
       "        True]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_newdim = np.expand_dims(np.array(train_data_filtered), axis=1)\n",
    "data_reshaped = np.broadcast_to(data_newdim, (emb_matrix.shape[0], emb_matrix.shape[1], train_data_filtered.shape[1]))\n",
    "data_reshaped[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_matrix = data_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix = np.concatenate((data_reshaped, emb_matrix), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05475705537294453 -0.06362175216471 3.575856294985138\n",
      "  0.8664677648458644 0 0.0 -0.865384899170238 -0.3842477354707097\n",
      "  -1.0300503271633217 5 True False False True 0.2411593794822693\n",
      "  -1.0092555284500122 -1.6876295804977417 0.7724331617355347\n",
      "  -0.658387303352356 0.3222971558570862 0.825392484664917\n",
      "  0.5634337067604065]\n",
      " [-0.05475705537294453 -0.06362175216471 3.575856294985138\n",
      "  0.8664677648458644 0 0.0 -0.865384899170238 -0.3842477354707097\n",
      "  -1.0300503271633217 5 True False False True 0.4071543514728546\n",
      "  1.6306689977645874 -0.12804804742336273 -0.6038780808448792\n",
      "  -0.807412326335907 -0.21964296698570251 0.4271683692932129\n",
      "  -0.06367146968841553]]\n"
     ]
    }
   ],
   "source": [
    "print(full_matrix[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_matrix = np.expand_dims(full_matrix, axis=(2, 1))\n",
    "full_matrix = full_matrix[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353969, 20, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "print(full_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.05475705537294453]\n",
      "  [-0.06362175216471]\n",
      "  [3.575856294985138]\n",
      "  [0.8664677648458644]\n",
      "  [0]\n",
      "  [0.0]\n",
      "  [-0.865384899170238]\n",
      "  [-0.3842477354707097]\n",
      "  [-1.0300503271633217]\n",
      "  [5]\n",
      "  [True]\n",
      "  [False]\n",
      "  [False]\n",
      "  [True]\n",
      "  [0.2411593794822693]\n",
      "  [-1.0092555284500122]\n",
      "  [-1.6876295804977417]\n",
      "  [0.7724331617355347]\n",
      "  [-0.658387303352356]\n",
      "  [0.3222971558570862]\n",
      "  [0.825392484664917]\n",
      "  [0.5634337067604065]]\n",
      "\n",
      " [[-0.05475705537294453]\n",
      "  [-0.06362175216471]\n",
      "  [3.575856294985138]\n",
      "  [0.8664677648458644]\n",
      "  [0]\n",
      "  [0.0]\n",
      "  [-0.865384899170238]\n",
      "  [-0.3842477354707097]\n",
      "  [-1.0300503271633217]\n",
      "  [5]\n",
      "  [True]\n",
      "  [False]\n",
      "  [False]\n",
      "  [True]\n",
      "  [0.4071543514728546]\n",
      "  [1.6306689977645874]\n",
      "  [-0.12804804742336273]\n",
      "  [-0.6038780808448792]\n",
      "  [-0.807412326335907]\n",
      "  [-0.21964296698570251]\n",
      "  [0.4271683692932129]\n",
      "  [-0.06367146968841553]]]\n"
     ]
    }
   ],
   "source": [
    "print(full_matrix[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(full_matrix, target.values, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318572, 20, 22, 1) (318572,) (35397, 20, 22, 1) (35397,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = 200000\n",
    "\n",
    "X_train = X_train[filter:]\n",
    "y_train = y_train[filter:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118572, 20, 22, 1) (118572,) (35397, 20, 22, 1) (35397,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "n_timesteps = X_train.shape[1]\n",
    "input_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same',\n",
    "                            input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same',\n",
    "                            input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Dense(64, activation='relu'),\n",
    "#   tf.keras.layers.Dense(1),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "# optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4)\n",
    "# model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 20, 22, 32)        320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 11, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3520)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               450688    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 460,385\n",
      "Trainable params: 460,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "464/464 [==============================] - 16s 34ms/step - loss: 12.5405 - val_loss: 7.8798\n",
      "Epoch 2/50\n",
      "464/464 [==============================] - 15s 33ms/step - loss: 7.5518 - val_loss: 7.6771\n",
      "Epoch 3/50\n",
      "464/464 [==============================] - 15s 32ms/step - loss: 7.4582 - val_loss: 7.2882\n",
      "Epoch 4/50\n",
      "464/464 [==============================] - 15s 32ms/step - loss: 7.2287 - val_loss: 7.0845\n",
      "Epoch 5/50\n",
      "464/464 [==============================] - 15s 32ms/step - loss: 6.9303 - val_loss: 7.1850\n",
      "Epoch 6/50\n",
      "464/464 [==============================] - 15s 32ms/step - loss: 6.7489 - val_loss: 6.8193\n",
      "Epoch 7/50\n",
      "464/464 [==============================] - 15s 32ms/step - loss: 6.6031 - val_loss: 6.7493\n",
      "Epoch 8/50\n",
      "464/464 [==============================] - 15s 33ms/step - loss: 6.4187 - val_loss: 6.6272\n",
      "Epoch 9/50\n",
      "464/464 [==============================] - 16s 34ms/step - loss: 6.3418 - val_loss: 7.1275\n",
      "Epoch 10/50\n",
      "464/464 [==============================] - 17s 38ms/step - loss: 6.1032 - val_loss: 6.6423\n",
      "Epoch 11/50\n",
      "464/464 [==============================] - 17s 37ms/step - loss: 6.0881 - val_loss: 6.4308\n",
      "Epoch 12/50\n",
      "464/464 [==============================] - 16s 35ms/step - loss: 6.0355 - val_loss: 6.7872\n",
      "Epoch 13/50\n",
      "464/464 [==============================] - 16s 36ms/step - loss: 6.0314 - val_loss: 6.4144\n",
      "Epoch 14/50\n",
      "464/464 [==============================] - 17s 37ms/step - loss: 5.9038 - val_loss: 6.6531\n",
      "Epoch 15/50\n",
      "464/464 [==============================] - 16s 34ms/step - loss: 5.9612 - val_loss: 6.3891\n",
      "Epoch 16/50\n",
      "464/464 [==============================] - 21s 46ms/step - loss: 5.8184 - val_loss: 6.6749\n",
      "Epoch 17/50\n",
      "464/464 [==============================] - 18s 40ms/step - loss: 5.7710 - val_loss: 6.8098\n",
      "Epoch 18/50\n",
      "464/464 [==============================] - 20s 43ms/step - loss: 5.7724 - val_loss: 6.3086\n",
      "Epoch 19/50\n",
      "464/464 [==============================] - 20s 44ms/step - loss: 5.6862 - val_loss: 6.5847\n",
      "Epoch 20/50\n",
      "464/464 [==============================] - 18s 39ms/step - loss: 5.5705 - val_loss: 6.6366\n",
      "Epoch 21/50\n",
      "395/464 [========================>.....] - ETA: 2s - loss: 5.3368"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.astype(np.float32), y_train.astype(np.float32), epochs=50, batch_size=256,\n",
    "         validation_data=(X_eval.astype(np.float32), y_eval.astype(np.float32)), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"loss\"], 'b', label='Training loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], 'g', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_eval.astype(np.float32),  y_eval.astype(np.float32), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train.astype(np.float32))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[\"favorites_count\"], model.predict(X_train))\n",
    "# plt.scatter(X_train[\"favorites_count\"], y_train.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\")\n",
    "tweets = eval_data[\"TweetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data[\"url_count\"] = eval_data[\"urls\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"text_len\"] = eval_data[\"text\"].apply(lambda s: len(s))\n",
    "eval_data[\"hashtags_count\"] = eval_data[\"hashtags\"].apply(lambda s: s[1:-1].count(\"\\'\")/2)\n",
    "eval_data[\"day\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).day)\n",
    "eval_data[\"hour\"] = eval_data[\"timestamp\"].apply(lambda t: datetime.utcfromtimestamp(t/1000).hour)\n",
    "eval_data[\"Macron\"] =  eval_data[\"text\"].apply(lambda s: (\"macron\" in s.lower().split()))\n",
    "eval_data[\"Zemmour\"] =  eval_data[\"text\"].apply(lambda s: (\"zemmour\" in s.lower().split()))\n",
    "eval_data[\"Melenchon\"] =  eval_data[\"text\"].apply(lambda s: (\"melenchon\" in s.lower().split()))\n",
    "eval_data[\"rt\"] =  eval_data[\"text\"].apply(lambda s: (\"rt\" in s.lower().split()))\n",
    "\n",
    "# print(\"sentiment analysis...\")\n",
    "# eval_data[\"compound\"] =  eval_data[\"text\"].apply(lambda s: sia.polarity_scores(s)['compound'])\n",
    "\n",
    "eval_data = eval_data.drop([\"text\", \"urls\", \"mentions\", \"hashtags\", \"timestamp\", \"TweetID\"], axis=1)\n",
    "\n",
    "# normalize\n",
    "eval_data.loc[:, normal_columns] = (eval_data.loc[:, normal_columns] - mu) / sigma\n",
    "\n",
    "print(eval_data)\n",
    "\n",
    "pred = model.predict(eval_data.values.astype(np.float32))\n",
    "\n",
    "print(pred)\n",
    "\n",
    "# output normalization\n",
    "for i,p in enumerate(pred):\n",
    "    if p<0: pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/predictions.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"retweets_count\"])\n",
    "    for index, prediction in enumerate(pred):\n",
    "        writer.writerow([str(tweets[index]) , str(int(prediction))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b76f9357de510751682414c7cddbaacea429d985ca72e90da955bd41bf6fe1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
